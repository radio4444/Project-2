{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# CSCI 381/780 (Fall 2022) - Project 2\n",
    "\n",
    "**Due Date: Monday, November 14 by 4 PM**\n",
    "\n",
    "## Description\n",
    "In this project you will construct machine learning models on two different real-world datasets using unsupervised learning and regression.\n",
    "\n",
    "## Instructions\n",
    "1. In this project you will write code to construct machine learning models and write responses to questions concerning the performance of said models. Please complete all sections below, adding new *Code* or *Markdown* cells as appropriate to answer the questions.\n",
    "2. There are many Scikit-learn functions that leverage randomness to generate results. For these functions, a pseudorandom generator can be initialized using a seed value by passing the parameter `random_state=XXX`, where `XXX` is some number between 1 and 2^31-1. For each of these functions, **you will utilize your CUNY ID number** to initialize the function. Functions include:\n",
    "- `ShuffleSplit`\n",
    "- `KFold`\n",
    "- `KMeans`\n",
    "- `GridSearchCV`\n",
    "- `Lasso`\n",
    "- `MLPRegressor`\n",
    "3. You will **work independently** on the project. Please make use of the *Python Data Science Reference Materials* posted on Blackboard, or **come to office hours should you need further assistance**.\n",
    "4. You will submit a single Jupyter notebook containing all code and written responses via Blackboard by the due date listed above.\n",
    "\n",
    "## Grading\n",
    "\n",
    "### Running Code\n",
    "Your Jupyter notebook must be able to run from start to finish **without error**. Please turn any cell that contains scratch work or other non-executable items to *Raw*. **Notebooks that cannot run to completion will receive a grade of 0**.\n",
    "\n",
    "\n",
    "### Rubric\n",
    "\n",
    "|**Part**|1.1|1.2|2.1|2.2|2.3|2.4|2.5|2.6|**Total**|\n",
    "|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|\n",
    "|**%**|10|30|15|5|10|10|10|10|100|\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Part 1: Clustering"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this part of the project, you will be using data collected by the US Geological Survey and the US Forest Service. The data describes various cartographic and geologic features related to forest cover in US wilderness areas, with each sample representing a 30 x 30 meter cell.\n",
    "\n",
    "The **goal** will be to *identify clusters* that represent forest cover types, and using these clusters *extract relationships* between forest covers and the provided cartographic/geologic features."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [],
   "source": [
    "#library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "cover_column_names=[\"Elevation\",\"Aspect\",\"Slope\",\n",
    "              \"Horizontal_Distance_To_Hydrology\",\"Vertical_Distance_To_Hydrology\",\n",
    "              \"Horizontal_Distance_To_Roadways\",\"Hillshade_9am\",\"Hillshade_Noon\",\n",
    "              \"Hillshade_3pm\",\"Horizontal_Distance_To_Fire_Points\"]\n",
    "wilderness_cols =[\"Wilderness_\"+str(i) for i in range(4)]\n",
    "soil_col =[\"Soil_\"+str(i) for i in range(40)]\n",
    "cover_columns_names = cover_column_names + wilderness_cols + soil_col"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.1 Load Data\n",
    "Set the variable `COVER_FILE` to the **full path** to the forest cover dataset (**forest_cover_dataset.csv**) on your system. Load the file into a dataframe (you may initialize the column names using the header list `cover_column_names`), then:\n",
    "1. Determine the number and types of features.\n",
    "2. Perform a **ShuffleSplit** of the data into training/validation/test sets, 60%/20%/20%.\n",
    "3. **Center** the training/validation/test splits (fit on the training set, then transform the validation/test sets)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [
    {
     "data": {
      "text/plain": "        Elevation  Aspect  Slope  Horizontal_Distance_To_Hydrology  \\\n0            2825     265     17                               319   \n1            2719     198     34                               134   \n2            3146     152     14                               212   \n3            2882      18     18                                95   \n4            2912     349     17                               283   \n...           ...     ...    ...                               ...   \n280246       2919     224     18                                85   \n280247       2151     114     29                                42   \n280248       3008     221     14                               418   \n280249       2923      58     12                               134   \n280250       3294     198      6                               484   \n\n        Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n0                                  108                             2298   \n1                                   76                             2352   \n2                                   41                              940   \n3                                   -3                              485   \n4                                   57                             2729   \n...                                ...                              ...   \n280246                              24                              451   \n280247                              29                              499   \n280248                              99                             5346   \n280249                              12                             2213   \n280250                              80                              849   \n\n        Hillshade_9am  Hillshade_Noon  Hillshade_3pm  \\\n0                 174             245            209   \n1                 187             245            167   \n2                 237             239            130   \n3                 203             199            128   \n4                 187             210            160   \n...               ...             ...            ...   \n280246            193             254            193   \n280247            254             197             49   \n280248            202             253            185   \n280249            228             214            117   \n280250            218             245            163   \n\n        Horizontal_Distance_To_Fire_Points  ...  Soil_30  Soil_31  Soil_32  \\\n0                                      342  ...        0        0        1   \n1                                      693  ...        0        0        0   \n2                                     2007  ...        0        0        0   \n3                                      342  ...        1        0        0   \n4                                     2201  ...        0        0        0   \n...                                    ...  ...      ...      ...      ...   \n280246                                1436  ...        0        0        0   \n280247                                 731  ...        0        0        0   \n280248                                1300  ...        0        0        0   \n280249                                 424  ...        0        0        0   \n280250                                2704  ...        0        1        0   \n\n        Soil_33  Soil_34  Soil_35  Soil_36  Soil_37  Soil_38  Soil_39  \n0             0        0        0        0        0        0        0  \n1             0        0        0        0        0        0        0  \n2             0        0        0        0        0        0        0  \n3             0        0        0        0        0        0        0  \n4             0        0        0        0        0        0        0  \n...         ...      ...      ...      ...      ...      ...      ...  \n280246        0        0        0        0        0        0        0  \n280247        0        0        0        0        0        0        0  \n280248        0        0        0        0        0        0        0  \n280249        0        0        0        0        0        0        0  \n280250        0        0        0        0        0        0        0  \n\n[280251 rows x 54 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Elevation</th>\n      <th>Aspect</th>\n      <th>Slope</th>\n      <th>Horizontal_Distance_To_Hydrology</th>\n      <th>Vertical_Distance_To_Hydrology</th>\n      <th>Horizontal_Distance_To_Roadways</th>\n      <th>Hillshade_9am</th>\n      <th>Hillshade_Noon</th>\n      <th>Hillshade_3pm</th>\n      <th>Horizontal_Distance_To_Fire_Points</th>\n      <th>...</th>\n      <th>Soil_30</th>\n      <th>Soil_31</th>\n      <th>Soil_32</th>\n      <th>Soil_33</th>\n      <th>Soil_34</th>\n      <th>Soil_35</th>\n      <th>Soil_36</th>\n      <th>Soil_37</th>\n      <th>Soil_38</th>\n      <th>Soil_39</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2825</td>\n      <td>265</td>\n      <td>17</td>\n      <td>319</td>\n      <td>108</td>\n      <td>2298</td>\n      <td>174</td>\n      <td>245</td>\n      <td>209</td>\n      <td>342</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2719</td>\n      <td>198</td>\n      <td>34</td>\n      <td>134</td>\n      <td>76</td>\n      <td>2352</td>\n      <td>187</td>\n      <td>245</td>\n      <td>167</td>\n      <td>693</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3146</td>\n      <td>152</td>\n      <td>14</td>\n      <td>212</td>\n      <td>41</td>\n      <td>940</td>\n      <td>237</td>\n      <td>239</td>\n      <td>130</td>\n      <td>2007</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2882</td>\n      <td>18</td>\n      <td>18</td>\n      <td>95</td>\n      <td>-3</td>\n      <td>485</td>\n      <td>203</td>\n      <td>199</td>\n      <td>128</td>\n      <td>342</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2912</td>\n      <td>349</td>\n      <td>17</td>\n      <td>283</td>\n      <td>57</td>\n      <td>2729</td>\n      <td>187</td>\n      <td>210</td>\n      <td>160</td>\n      <td>2201</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>280246</th>\n      <td>2919</td>\n      <td>224</td>\n      <td>18</td>\n      <td>85</td>\n      <td>24</td>\n      <td>451</td>\n      <td>193</td>\n      <td>254</td>\n      <td>193</td>\n      <td>1436</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>280247</th>\n      <td>2151</td>\n      <td>114</td>\n      <td>29</td>\n      <td>42</td>\n      <td>29</td>\n      <td>499</td>\n      <td>254</td>\n      <td>197</td>\n      <td>49</td>\n      <td>731</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>280248</th>\n      <td>3008</td>\n      <td>221</td>\n      <td>14</td>\n      <td>418</td>\n      <td>99</td>\n      <td>5346</td>\n      <td>202</td>\n      <td>253</td>\n      <td>185</td>\n      <td>1300</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>280249</th>\n      <td>2923</td>\n      <td>58</td>\n      <td>12</td>\n      <td>134</td>\n      <td>12</td>\n      <td>2213</td>\n      <td>228</td>\n      <td>214</td>\n      <td>117</td>\n      <td>424</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>280250</th>\n      <td>3294</td>\n      <td>198</td>\n      <td>6</td>\n      <td>484</td>\n      <td>80</td>\n      <td>849</td>\n      <td>218</td>\n      <td>245</td>\n      <td>163</td>\n      <td>2704</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>280251 rows × 54 columns</p>\n</div>"
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cover_file = f'C:/Users/tanzi/CS Lang IDE/PycharmProjects/Project-2/UTF-8_forest_cover_dataset.csv'\n",
    "#search later, how to auto complete full path. https://www.youtube.com/watch?v=3Spa10-mwsw\n",
    "\n",
    "cover_file = f'C:/Users/tanzi/CS Lang IDE/PycharmProjects/Jonathan/Project2/Project-2/UTF-8_forest_cover_dataset.csv'\n",
    "forest_data = pd.read_csv(cover_file, names=cover_columns_names)\n",
    "forest_data\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features:  54\n"
     ]
    }
   ],
   "source": [
    "# Determine the number of features\n",
    "num_features = len(cover_columns_names)\n",
    "print('Number of features: ', num_features)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elevation : [2825 2719 3146 ... 3626 3541 3607]\n",
      "Aspect : [265 198 152  18 349 202 102  90   9 117 315  40 110   3 359 106 108 150\n",
      "  32 347 127  62 123 176  53 100 180 166 189 243 294  72 112  22  45 274\n",
      "  60 344  28 299  65  34 169  73  43  82 262 232  83  37 329  49 269  66\n",
      " 140 133  33  61 350  63  74 326 193 225 226 342 318 276 316 167 303  55\n",
      " 131  69 251  19 220  52 135  11 270  26  14 357  59  42  51 158 204 138\n",
      " 356  78  12 306 165 238 235 352 219 307 119 311 351  36  95  25 163 162\n",
      " 272  17 340 113  41 348   0 324  35  68  13  20 334 343 304  85  96 146\n",
      "  99 143 301  79  98 336 196  21 101 116 170 317 245  38  92 111 211 354\n",
      " 121   8 249 157 277  31   4 181 322 105 288 332 185 187 241 199 172 289\n",
      " 207 281 291 222 107  93 302 195  56 247 314 327   7 287 263 333 309 209\n",
      " 148 331   1 266   5  91  15 268  16 145 184 254 194  71 337 183 346 149\n",
      "  80 285  58  57  89 118 330  50 125 296 182  27 231 248  54  70  97 103\n",
      " 156 147  76  23  67 338 256 174 323 358 177 267 300 215  30 206 203  44\n",
      " 252 171 134  39 155 328   6  87 234 122 128  64 139 295 130 228  81 159\n",
      " 218 286 240 173 257  29 141 104  94 339 205 144 221 164 305 335 341 153\n",
      "   2  47 197 129 308 137 253 216 178 201  48 142 284 208 271 258 297 132\n",
      "  75  84 154 109 310 321 217 292  88 260 313 278  10 190 345  24 114 160\n",
      " 242 120 325  86 320 213 161 136 175 293 282 210 261 230 259 312 233 319\n",
      " 236 353 168 255 355 279 214 124 229 264 191 280 192 250 273  77 227 223\n",
      " 283 275 290 126 246 151 179 237 244 115 188 239 298  46 200 212 186 224\n",
      " 360]\n",
      "Slope : [17 34 14 18 11 12  6  4 15 21  9 25 19 10  8 16  1 20 24  5  2 13  3  7\n",
      " 33 23 38 28 29 22 31 30 35 26 36 27 32 37  0 39 40 48 42 43 45 46 41 47\n",
      " 49 44 57 50 59 53 52 51 61 65 54 64 56 55 60 66 63]\n",
      "Horizontal_Distance_To_Hydrology : [ 319  134  212   95  283  192  342  330  255  234   30    0  726   60\n",
      "  630  295  541   85  216  400   42  361  351  210  162  362  190  458\n",
      "  153   90   67  277  331  180  124  120  268  607  424  323  828  150\n",
      "  564  480  570  228  390  677  379  450  631  391  170  258  270  272\n",
      "  601  218  636  256  297  324  108  240  547  540  360  309  301  700\n",
      "  175  577  242  306  633  247  902  430  655  335  285  182  513  466\n",
      "  201  420  499  573  382  495  313  127  600  395  750  300  716  417\n",
      "  467  402  780  722  376  534  484  794  781  474  876  339  624  514\n",
      "  618  497  819 1170  408  511  979  509  671  595  433  591  800  768\n",
      "  366  721  552  900  350  642  582  693  371  875  446  849  870  531\n",
      "  799  955  459  616  524  384  443  702  757  560  684  510  404  469\n",
      "  537  576  641  503  742  930  732  551  765  787  741  553  457  437\n",
      "  816  658  664  984  969  418  589  604  959  942  690  569  488  960\n",
      "  571  612  957  920  663  454 1271  792  451  698  660  759  485  365\n",
      "  895  713  810  470  769  516  711  845  481  426  566  836  691  745\n",
      "  626 1092  518  872  720  830  782  532  659  866  598  674  421  824\n",
      "  649  708  646  666  543  834  771  743  558  638  859 1068  592 1034\n",
      "  774  755  886  492  807  865  841  735  785 1006  840  949  680  594\n",
      "  931  854 1315  706 1084  764  751  603  987  908  731  752  977  525\n",
      "  864  990  760  725  685  892  797 1154  703  661  805 1082  679  994\n",
      " 1131  579 1061 1259  730  912  778 1213  808  972  953  644  779  858\n",
      "  962  888  899  997  924  738 1142  911 1198  914 1116  933  696  976\n",
      " 1275 1024 1260 1087  850  811  812  999  837  947  789 1065  832  878\n",
      "  767 1080  891 1273  966  806  860  983 1121  815  890 1265  853  648\n",
      " 1129 1300 1310  932 1044 1050 1113  907 1182 1040  973  883  904  993\n",
      " 1073  874 1063 1020 1203 1048 1045 1055 1304 1074 1077 1071 1205 1008\n",
      "  871 1230 1114 1302  939  847  964 1120 1018 1124  937  882 1103 1158\n",
      "  793  842  916 1329 1180 1026  918 1100  934 1041 1282 1099 1025  927\n",
      " 1012 1277  938 1245 1115 1032 1128 1022 1194 1027 1053  981 1110 1101\n",
      " 1015 1150 1224 1060 1062 1106 1072 1237 1054 1047 1233 1172  825 1052\n",
      " 1195 1201 1221 1243 1216  926 1167 1200  967 1019  940 1001  992 1138\n",
      " 1342 1107 1148 1003 1261 1036 1031 1159  968 1318 1383 1140 1126 1208\n",
      " 1288 1127 1253 1235 1231 1222 1226 1146 1215 1165 1199 1206 1240 1091\n",
      " 1332 1266 1316 1075 1155 1104 1250 1269 1090 1218 1348 1123 1234 1328\n",
      " 1033 1057 1112 1130 1173 1187 1248 1283 1358 1276 1149 1064 1136 1184\n",
      " 1254 1183 1177 1290 1209 1189 1361 1179 1168 1307 1371 1211 1292 1134\n",
      " 1236 1262 1319 1289 1239 1095 1343 1397 1190 1295 1249 1354 1176 1324\n",
      " 1320 1390 1188 1368 1301 1191 1144 1207]\n",
      "Vertical_Distance_To_Hydrology : [ 108   76   41   -3   57   36   47   46   26  -12   72    5    0   78\n",
      "   22   45   62    7   18   34   -8   13    1   40    4  171   19   11\n",
      "   -2   49  -22   70   58   -9   63  -21   32   44   51   53    2   15\n",
      "   16   17  150   10    9  -33  163    6  103   23  135   25  180   82\n",
      "    8   33  109   35   24   12   28  129  -14   86   92   59    3   97\n",
      " -145   14   30  -37   54   66   31   68   -1   42  213   84   77  128\n",
      "   73   -5  134   56   69  131   48   -4  115   21  206   39  -11   90\n",
      "  -51  177  -23   52  -18  123  104   88  101  116  236   38   50  -27\n",
      "  193  105   96  148   91   37   -7   89  111   83   79   67   43  158\n",
      "  -47  200  140  124   61   65  190   85   55  100   75  102  154  122\n",
      "  281  118  310  165  175   81   27   95  120  166   29  205  138  300\n",
      "   20  -13  146  -10  -16   94  132  239  -44  202  -31  -19  182  -30\n",
      "   60  143  302 -139  139   80  110   74  194  191   98  -43   64   71\n",
      "  174  151  -17  121  183  136  -38  117  203  289  -60   -6  107  -46\n",
      "  160  262  -56  181  114  -62  162  212  155  -65   99  125  -88  215\n",
      "  296  -25  238  172   93  219  240  -35  303  127  168  113  228  144\n",
      "  290  112  119  218  164  188  185  133  224  159  210  -48  225  227\n",
      "  -32  -15  141  229  147  -34  263  -39  189  126  161  170  169  197\n",
      "  -80   87  570  209  153  142  187  -45  -50  186  -58  -57  157  195\n",
      "  207  223  -24  -41  288  192  -59  -93  279  156  244  -42  199  -49\n",
      "  221  217  149  137 -106 -124  305  415  145  -29  -28  -55  -26  252\n",
      "  -78  -75  173  258  246  370  167  368  211  286  275  247  -36  249\n",
      " -111  214  179  233  311  130  198  276  106  253  178  313 -101  152\n",
      "  266  -68 -114 -130  -86  -74  -20  204  176  235 -119  -77 -104  230\n",
      "  314  237  -72  -61  222  270  -52  363  232  216  331  366  255  264\n",
      "  201  184  -90 -113  -82  401  196  250 -116  341  364  394  265  304\n",
      "  297  241  -66  278  361  283  242  231 -125  -76  -64  257  259  343\n",
      "  -97  220  251  -40  -85  -54  379  285  271  269  373 -121  306  329\n",
      "  337  322  -73  307  330  408  -53  -71  291  -83  -99 -105  292  245\n",
      " -110  234  414  325  226  353  268  -98  316  398 -102  318 -123  248\n",
      "  443  345 -107  254  -67  375  267  277  -96  256  -81  261  295  260\n",
      "  334  274  550  -69  -94  333  367  354  208  243  319  282 -133  346\n",
      " -149  -70  -91 -108  402  336  -95 -103  356  358  273  -89  453 -100\n",
      "  -63 -112 -118  312  391 -166  -92  317 -109  324  293  389 -143  419\n",
      "  294  -79  338  272  327  284  359  308 -140  287  309  543  -84 -137\n",
      " -155  377  381 -115  355  493  386  371 -134  348 -159  421 -117  347\n",
      "  554  362  395  360  466 -132  365  523  335 -129  332  369 -128  323\n",
      "  428  597 -131  280  -87  376 -136  301  400  512  328  351  528  446\n",
      "  383  350  298 -122  357  315  385  326 -135  568  478  349  320  299\n",
      "  378  393  407  340  344  396  342  517 -126  434  557  390 -120  321\n",
      "  339  491 -152 -150  485  537  374  405  427 -146  461  496  413  479\n",
      "  372  585  539  382  454  392  420  397  403  352  526  506 -153  380\n",
      "  592  561  565  589 -127 -141  571 -144  411  549  455  431  524  527\n",
      "  595  514  492  410  387  544  388  409  547  432  590  573  463  536\n",
      " -157 -151  598 -138  507  584  540  552  586  384 -173  578  406  404\n",
      "  417  462 -156  508 -163  582  504  399]\n",
      "Horizontal_Distance_To_Roadways : [2298 2352  940 ... 6805 6788 6409]\n",
      "Hillshade_9am : [174 187 237 203 215 240 230 207 227 178 216 248 214 206 252 245 239 212\n",
      " 201 247 232 224 226 238 223 221 219 246 211 194 197 231 202 234 241 220\n",
      " 165 222 160 218 208 225 184 229 199 190 145 166 243 200 210 249 213 217\n",
      " 204 196 180 185 244 250 170 135 183 209 143 114 179 191 251 147 176 181\n",
      " 228 235 126 182 242 124 195 162 205 172 146 253 132 167 198 188 125 161\n",
      " 236 107 171 163 155 169 141 159 177 233 175 192 149 189 153 144 137 164\n",
      " 186 168 193 138 127 254  94 173 157 129 151 120  90 156 150 140 158 134\n",
      " 148 102 112 154 142  93 128 139  87 130 136 152 122 117 121 131  88  75\n",
      " 104 116  70 115  99 133 109  92 106 103 111 123 100 108  96 119  85 110\n",
      " 105  54  73 113  52  76  89 118   0  67  95  97  74  79  80  98  91  78\n",
      "  71  64 101  84  83  56  65  82  81  86  77  46  66  68  36  59  72  69\n",
      "  61  60  57  55  62]\n",
      "Hillshade_Noon : [245 239 199 210 250 224 230 217 236 226 188 216 232 223 201 221 237 196\n",
      " 225 204 243 218 244 251 222 191 190 246 219 227 180 233 202 207 229 228\n",
      " 242 247 206 187 205 252 253 220 231 212 248 208 213 240 200 235 194 150\n",
      " 167 249 182 161 176 203 168 234 211 215 173 195 238 175 214 209 192 197\n",
      " 254 174 198 241 146 170 160 145 184 159 189 172 193 164 163 186 152 179\n",
      " 185 171 162 144 183 178 181 177 169 147 157 141 148 153 158 136 154 156\n",
      " 166 155 129 126 108 135 138 139 149 125 104 165 134 131 133 137  96 132\n",
      " 122 151 130 112 143  98   0 142 117 140 120 107  63 124 121 123 119 116\n",
      "  92  76 111  85 128  99  87 101 114  42 106  91 113 100 115  71 127 103\n",
      "  30 109  74 118  80 105 102 110  97  81  78  93  88  53  64  95  40  90]\n",
      "Hillshade_3pm : [209 167 130 128 160 168 111 134 146 143 188  98  89 155  62 100 122 113\n",
      " 162  99 154 126 116 156 139 159 169 197 144 109  95 150 163 103 195 141\n",
      " 110  90 184 108 133 182 218 121  91 153 104 140 137 136 124  64 112 164\n",
      " 185 189 179 187 200 201 127  97 114 107 174  87 165 148  65 172  94  84\n",
      " 175  59  18 186  69  88 208 157  58 138 241 145 123  78 152 181  92 105\n",
      " 147 149 177 166 191 101 132 125 102 192 151 221  83 142 194 212 135 131\n",
      " 203 225 115 158  17 196  72 180  81 170 206 171 202  80 204  67 224  53\n",
      " 173  42 217 207 119 161 220 183 120 129 117 211  57 236  76 198  74 118\n",
      " 205  46 210  79  93  56  71  43  77 229  85 199 106 176 178  31  48 213\n",
      "  96  21 222   2  41 242  73 223  47  40 214  55 193   9  37  14  75  63\n",
      "  52  34  27  60 190 232 227 244  45 216  86  61  51 237 249  82 219 228\n",
      " 233  16 226  32 240 234  38  68 231  70  44  12  30  22  50  29 239  28\n",
      " 215  66  36   0  20  23 235   4  49 230  13 248  54 246  11 243   5  39\n",
      " 238  25  33   6  26  24  35 247 245   8  15 254  19   1 251 252  10 250\n",
      "   7   3 253]\n",
      "Horizontal_Distance_To_Fire_Points : [ 342  693 2007 ... 6760 6203 4880]\n",
      "Wilderness_0 : [0 1]\n",
      "Wilderness_1 : [0 1]\n",
      "Wilderness_2 : [1 0]\n",
      "Wilderness_3 : [0 1]\n",
      "Soil_0 : [0 1]\n",
      "Soil_1 : [0 1]\n",
      "Soil_2 : [0 1]\n",
      "Soil_3 : [0 1]\n",
      "Soil_4 : [0 1]\n",
      "Soil_5 : [0 1]\n",
      "Soil_6 : [0 1]\n",
      "Soil_7 : [0 1]\n",
      "Soil_8 : [0 1]\n",
      "Soil_9 : [0 1]\n",
      "Soil_10 : [0 1]\n",
      "Soil_11 : [0 1]\n",
      "Soil_12 : [0 1]\n",
      "Soil_13 : [0 1]\n",
      "Soil_14 : [0]\n",
      "Soil_15 : [0 1]\n",
      "Soil_16 : [0 1]\n",
      "Soil_17 : [0 1]\n",
      "Soil_18 : [0 1]\n",
      "Soil_19 : [0 1]\n",
      "Soil_20 : [0 1]\n",
      "Soil_21 : [0 1]\n",
      "Soil_22 : [0 1]\n",
      "Soil_23 : [0 1]\n",
      "Soil_24 : [0 1]\n",
      "Soil_25 : [0 1]\n",
      "Soil_26 : [0 1]\n",
      "Soil_27 : [0 1]\n",
      "Soil_28 : [0 1]\n",
      "Soil_29 : [0 1]\n",
      "Soil_30 : [0 1]\n",
      "Soil_31 : [0 1]\n",
      "Soil_32 : [1 0]\n",
      "Soil_33 : [0 1]\n",
      "Soil_34 : [0 1]\n",
      "Soil_35 : [0 1]\n",
      "Soil_36 : [0]\n",
      "Soil_37 : [0 1]\n",
      "Soil_38 : [0 1]\n",
      "Soil_39 : [0 1]\n"
     ]
    }
   ],
   "source": [
    "#change the variable name\n",
    "\n",
    "#Determine nature of object types\n",
    "crime_cat_columns=dict()\n",
    "crime_cat_columns_idx=dict()\n",
    "crime_num_columns_idx=dict()\n",
    "for col in cover_columns_names:\n",
    "    if forest_data[col].dtype == 'int64':\n",
    "        crime_cat_columns[col]=forest_data[col].unique()\n",
    "        crime_cat_columns_idx[col]=forest_data.columns.get_loc(col)\n",
    "        print(col,\":\", crime_cat_columns[col])\n",
    "    elif np.issubdtype(forest_data.at[0,col], np.number):\n",
    "        crime_num_columns_idx[col]=forest_data.columns.get_loc(col)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "outputs": [],
   "source": [
    "# Perform a **ShuffleSplit** of the data into training/validation/test sets, 60%/20%/20%.\n",
    "forest_data_list = np.array(forest_data)\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "split_test = ShuffleSplit(n_splits=1,test_size=0.2, random_state=23508893)\n",
    "for train_index, test_index in split_test.split(forest_data_list):\n",
    "    forest_train_proj_full = forest_data_list[train_index,:]\n",
    "    forest_test_proj = forest_data_list[test_index,:]\n",
    "\n",
    "\n",
    "split_validation = ShuffleSplit(n_splits=1,test_size=0.25, random_state=23508893)\n",
    "for train_index, validation_index in split_validation.split(forest_train_proj_full):\n",
    "    forest_train_proj = forest_train_proj_full[train_index,:]\n",
    "    forest_validation_proj = forest_train_proj_full[validation_index,:]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [],
   "source": [
    "# #Maybe comment this out?\n",
    "# print(\"Dataset\\t\\tPercent\")\n",
    "# print(\"Training\\t\" + str(np.sum(forest_train_proj) / len(forest_train_proj)))\n",
    "# print(\"Validation\\t\" + str(np.sum(forest_validation_proj) / len(forest_validation_proj)))\n",
    "# print(\"Test\\t\\t\" + str(np.sum(forest_test_proj) / len(forest_test_proj)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. How would want us to solve 1.1.3 [center the training]. Should I use customs transformer? If so, during the next step, should I use data_centered_train or forest_train_proj?\n",
    "2. forest_train_proj = dataset (X) | data_center_train = first center randomly\n",
    "3.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 8.91375558e+01, -1.45949057e+02, -2.10169492e+00, ...,\n        -1.66815343e-02, -1.46000595e-02, -9.05738924e-03],\n       [ 2.30137556e+02,  1.99050943e+02,  1.18983051e+01, ...,\n        -1.66815343e-02, -1.46000595e-02, -9.05738924e-03],\n       [ 2.01137556e+02,  1.67050943e+02, -2.10169492e+00, ...,\n        -1.66815343e-02, -1.46000595e-02, -9.05738924e-03],\n       ...,\n       [ 1.84137556e+02,  1.59050943e+02, -1.31016949e+01, ...,\n        -1.66815343e-02, -1.46000595e-02, -9.05738924e-03],\n       [ 3.34137556e+02, -6.79490574e+01, -8.10169492e+00, ...,\n        -1.66815343e-02, -1.46000595e-02, -9.05738924e-03],\n       [-7.12862444e+02, -9.49057389e-01,  1.98983051e+01, ...,\n        -1.66815343e-02, -1.46000595e-02, -9.05738924e-03]])"
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler(with_std=False)\n",
    "forest_train_proj_scaled=scaler.fit_transform(forest_train_proj)\n",
    "forest_validation_proj_scaled=scaler.transform(forest_validation_proj)\n",
    "forest_test_proj_scaled=scaler.transform(forest_test_proj)\n",
    "forest_train_proj_full_scaled=scaler.transform(forest_train_proj_full)\n",
    "\n",
    "forest_train_proj_full_scaled"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.2 $k$-Means Clustering"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Cluster the *training* dataset using ```KMeans``` from Scikit-learn using the values for $k$ below. You can utilize the default implementation in Scikit-learn, which is $k$-means$++$. Construct models for each value of $k$ specified in the ``k_values`` array below.\n",
    "2. Apply the trained models to the validation dataset.\n",
    "3. Compute the **mean** inertia for each value of $k$ on the training and validation datasets. For the training data, you can extract the *total* (**unnormalized**) inertia from the trained models via their respective ```inertia_```. For the validation models, you can utilize the function ```total_inertia``` provided below.\n",
    "4. Plot the mean inertias for all values of $k$ and for both the training and validation sets on a single plot. Based on the elbow method, which value of $k$ should be chosen so that the model will generalize to new data?\n",
    "5. The *Silhouette Coefficient* is another cluster performance metric that combines intra-cluster distance with inter-cluster distances from clusters in close proximity to each other. Utilize Scikit-learn's ```silhouette_score``` function [(documentation)](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html#sklearn.metrics.silhouette_score) to compute the silhouette coefficient for all values of $k$ on the *validation* set. Plot these values and determine via the elbow method which value of $k$ should be chosen. How does this value compare to the one chosen using mean inertia?\n",
    "6. Using whichever value of $k$ you think is the best based on steps 4) and 5), create a plot for each feature that contains [boxplots](https://matplotlib.org/stable/gallery/statistics/boxplot_demo.html#sphx-glr-gallery-statistics-boxplot-demo-py) of that feature for each cluster. Based upon these plots, determine which features you think are meaningful in discriminating between the clusters, as well as any other trends you observe."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Please Read!\n",
    "You may benefit from parallelizing the creation of the $k$-means models by using the Python package ```joblib```. I've included a code template below that you can customize. For additional details, please refer to [joblib's documentation](https://joblib.readthedocs.io/en/latest/parallel.html)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "dd723091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from joblib import Parallel, delayed, parallel_backend\n",
    "#\n",
    "# with parallel_backend(\"loky\", inner_max_num_threads=2):\n",
    "#     results = Parallel(n_jobs=4)(delayed(func)(x, y) for x, y in data)\n",
    "#     # which data?\n",
    "#     # || x = forest_train_proj and y = data_centered_train?\n",
    "#     # || x = k-mean and y = k-mean ++?\n",
    "#     # || x = forest_train_proj and y = k-means\n",
    "#     # func = center_function? or [cluster_centers_ or labels_] from k-means?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "38cf5490",
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_inertia(dataset,centers,labels,distance=None,mean=True):\n",
    "    # dataset= forest_validation_proj | centers = kmeans.cluster_centers_ [valid_predict] | label = valid_predict |mean=false\n",
    "    \"\"\"\n",
    "    Computes the total inertia (the intracluster variance) given a dataset and the cluster centers.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset : numpy.ndarray\n",
    "        The dataset to evaluate.\n",
    "    center : numpy.ndarray or list\n",
    "        The list of cluster centers.\n",
    "    distance : function\n",
    "        A function that computes the pairwise distance between two samples.\n",
    "        Default: Euclidean (l_2) distance\n",
    "    mean : bool\n",
    "        If True, returns the mean inertia.\n",
    "        Default: True\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    total_inertia : float\n",
    "       The mean inertia (if mean==True) or total inertia (if mean==False).\n",
    "\"\"\"\n",
    "    num_samples,_ = dataset.shape\n",
    "    total_inertia=0\n",
    "    if distance is None:\n",
    "        distance=lambda x,y: np.linalg.norm(x-y)**2\n",
    "    for i,sample in enumerate(dataset):\n",
    "        center = centers[labels[i]]\n",
    "        total_inertia += distance(sample,center)\n",
    "    \n",
    "    if mean:\n",
    "        return total_inertia/num_samples\n",
    "    else:\n",
    "        return total_inertia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "k_values = list(range(2,11))+[15,20]\n",
    "\n",
    "inertias_list = []\n",
    "k_model_list = []\n",
    "cluster_list = []\n",
    "\n",
    "for k in k_values:\n",
    "    k_model = KMeans(n_clusters=k, random_state=23508893).fit(forest_train_proj_scaled)\n",
    "    cluster = k_model.predict(forest_train_proj_scaled)\n",
    "    k_model_list.append(k_model)\n",
    "    inertias_list.append(k_model.inertia_)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [],
   "source": [
    "# Apply the trained models to validation dataset\n",
    "\n",
    "forest_validation_predict = []\n",
    "forest_validation_center = []\n",
    "for k_model in k_model_list:\n",
    "    forest_validation_predict.append(k_model.predict(forest_validation_proj_scaled))\n",
    "    forest_validation_center.append(k_model.cluster_centers_)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inertia_valid_list = []\n",
    "for i in range(len(k_values)):\n",
    "    inertia_valid_list.append(total_inertia(\n",
    "        forest_validation_proj_scaled, forest_validation_center[i], forest_validation_predict[i]\n",
    "    ))\n",
    "\n",
    "plt.plot(k_values, inertias_list, label ='training')\n",
    "plt.plot(k_values, inertia_valid_list, label ='validation')\n",
    "plt.xlabel('# of k_values')\n",
    "plt.ylabel('inertias')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "From elbow method graph, we could see that K = 3, should be chosen so that the model will generalize to new data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [130], line 5\u001B[0m\n\u001B[0;32m      3\u001B[0m silhouette_list \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(k_values)):\n\u001B[1;32m----> 5\u001B[0m     silhouette_list\u001B[38;5;241m.\u001B[39mappend(\u001B[43msilhouette_score\u001B[49m\u001B[43m(\u001B[49m\u001B[43mforest_validation_proj_scaled\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mforest_validation_predict\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m      7\u001B[0m plt\u001B[38;5;241m.\u001B[39mplot(k_values, silhouette_list)\n\u001B[0;32m      8\u001B[0m plt\u001B[38;5;241m.\u001B[39mxlabel(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mk\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32m~\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\metrics\\cluster\\_unsupervised.py:117\u001B[0m, in \u001B[0;36msilhouette_score\u001B[1;34m(X, labels, metric, sample_size, random_state, **kwds)\u001B[0m\n\u001B[0;32m    115\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    116\u001B[0m         X, labels \u001B[38;5;241m=\u001B[39m X[indices], labels[indices]\n\u001B[1;32m--> 117\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39mmean(silhouette_samples(X, labels, metric\u001B[38;5;241m=\u001B[39mmetric, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds))\n",
      "File \u001B[1;32m~\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\metrics\\cluster\\_unsupervised.py:237\u001B[0m, in \u001B[0;36msilhouette_samples\u001B[1;34m(X, labels, metric, **kwds)\u001B[0m\n\u001B[0;32m    233\u001B[0m kwds[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmetric\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m metric\n\u001B[0;32m    234\u001B[0m reduce_func \u001B[38;5;241m=\u001B[39m functools\u001B[38;5;241m.\u001B[39mpartial(\n\u001B[0;32m    235\u001B[0m     _silhouette_reduce, labels\u001B[38;5;241m=\u001B[39mlabels, label_freqs\u001B[38;5;241m=\u001B[39mlabel_freqs\n\u001B[0;32m    236\u001B[0m )\n\u001B[1;32m--> 237\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mzip\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mpairwise_distances_chunked\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreduce_func\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreduce_func\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    238\u001B[0m intra_clust_dists, inter_clust_dists \u001B[38;5;241m=\u001B[39m results\n\u001B[0;32m    239\u001B[0m intra_clust_dists \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mconcatenate(intra_clust_dists)\n",
      "File \u001B[1;32m~\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:1850\u001B[0m, in \u001B[0;36mpairwise_distances_chunked\u001B[1;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001B[0m\n\u001B[0;32m   1848\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1849\u001B[0m     X_chunk \u001B[38;5;241m=\u001B[39m X[sl]\n\u001B[1;32m-> 1850\u001B[0m D_chunk \u001B[38;5;241m=\u001B[39m pairwise_distances(X_chunk, Y, metric\u001B[38;5;241m=\u001B[39mmetric, n_jobs\u001B[38;5;241m=\u001B[39mn_jobs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m   1851\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (X \u001B[38;5;129;01mis\u001B[39;00m Y \u001B[38;5;129;01mor\u001B[39;00m Y \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;129;01mand\u001B[39;00m PAIRWISE_DISTANCE_FUNCTIONS\u001B[38;5;241m.\u001B[39mget(\n\u001B[0;32m   1852\u001B[0m     metric, \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1853\u001B[0m ) \u001B[38;5;129;01mis\u001B[39;00m euclidean_distances:\n\u001B[0;32m   1854\u001B[0m     \u001B[38;5;66;03m# zeroing diagonal, taking care of aliases of \"euclidean\",\u001B[39;00m\n\u001B[0;32m   1855\u001B[0m     \u001B[38;5;66;03m# i.e. \"l2\"\u001B[39;00m\n\u001B[0;32m   1856\u001B[0m     D_chunk\u001B[38;5;241m.\u001B[39mflat[sl\u001B[38;5;241m.\u001B[39mstart :: _num_samples(X) \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n",
      "File \u001B[1;32m~\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:2022\u001B[0m, in \u001B[0;36mpairwise_distances\u001B[1;34m(X, Y, metric, n_jobs, force_all_finite, **kwds)\u001B[0m\n\u001B[0;32m   2019\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m distance\u001B[38;5;241m.\u001B[39msquareform(distance\u001B[38;5;241m.\u001B[39mpdist(X, metric\u001B[38;5;241m=\u001B[39mmetric, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds))\n\u001B[0;32m   2020\u001B[0m     func \u001B[38;5;241m=\u001B[39m partial(distance\u001B[38;5;241m.\u001B[39mcdist, metric\u001B[38;5;241m=\u001B[39mmetric, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[1;32m-> 2022\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _parallel_pairwise(X, Y, func, n_jobs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n",
      "File \u001B[1;32m~\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:1563\u001B[0m, in \u001B[0;36m_parallel_pairwise\u001B[1;34m(X, Y, func, n_jobs, **kwds)\u001B[0m\n\u001B[0;32m   1560\u001B[0m X, Y, dtype \u001B[38;5;241m=\u001B[39m _return_float_dtype(X, Y)\n\u001B[0;32m   1562\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m effective_n_jobs(n_jobs) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m-> 1563\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m func(X, Y, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m   1565\u001B[0m \u001B[38;5;66;03m# enforce a threading backend to prevent data communication overhead\u001B[39;00m\n\u001B[0;32m   1566\u001B[0m fd \u001B[38;5;241m=\u001B[39m delayed(_dist_wrapper)\n",
      "File \u001B[1;32m~\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:328\u001B[0m, in \u001B[0;36meuclidean_distances\u001B[1;34m(X, Y, Y_norm_squared, squared, X_norm_squared)\u001B[0m\n\u001B[0;32m    322\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m Y_norm_squared\u001B[38;5;241m.\u001B[39mshape \u001B[38;5;241m!=\u001B[39m (\u001B[38;5;241m1\u001B[39m, Y\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]):\n\u001B[0;32m    323\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    324\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIncompatible dimensions for Y of shape \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mY\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m and \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    325\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mY_norm_squared of shape \u001B[39m\u001B[38;5;132;01m{\u001B[39;00moriginal_shape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    326\u001B[0m         )\n\u001B[1;32m--> 328\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_euclidean_distances\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mY\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_norm_squared\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mY_norm_squared\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msquared\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:369\u001B[0m, in \u001B[0;36m_euclidean_distances\u001B[1;34m(X, Y, X_norm_squared, Y_norm_squared, squared)\u001B[0m\n\u001B[0;32m    366\u001B[0m     distances \u001B[38;5;241m=\u001B[39m _euclidean_distances_upcast(X, XX, Y, YY)\n\u001B[0;32m    367\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    368\u001B[0m     \u001B[38;5;66;03m# if dtype is already float64, no need to chunk and upcast\u001B[39;00m\n\u001B[1;32m--> 369\u001B[0m     distances \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m2\u001B[39m \u001B[38;5;241m*\u001B[39m \u001B[43msafe_sparse_dot\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mY\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mT\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdense_output\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m    370\u001B[0m     distances \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m XX\n\u001B[0;32m    371\u001B[0m     distances \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m YY\n",
      "File \u001B[1;32m~\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\utils\\extmath.py:155\u001B[0m, in \u001B[0;36msafe_sparse_dot\u001B[1;34m(a, b, dense_output)\u001B[0m\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    152\u001B[0m     ret \u001B[38;5;241m=\u001B[39m a \u001B[38;5;241m@\u001B[39m b\n\u001B[0;32m    154\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m--> 155\u001B[0m     \u001B[43msparse\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43missparse\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    156\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m sparse\u001B[38;5;241m.\u001B[39missparse(b)\n\u001B[0;32m    157\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m dense_output\n\u001B[0;32m    158\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(ret, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtoarray\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    159\u001B[0m ):\n\u001B[0;32m    160\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m ret\u001B[38;5;241m.\u001B[39mtoarray()\n\u001B[0;32m    161\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m ret\n",
      "File \u001B[1;32m~\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\scipy\\sparse\\_base.py:1301\u001B[0m, in \u001B[0;36misspmatrix\u001B[1;34m(x)\u001B[0m\n\u001B[0;32m   1297\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1298\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39mzeros(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mshape, dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdtype, order\u001B[38;5;241m=\u001B[39morder)\n\u001B[1;32m-> 1301\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21misspmatrix\u001B[39m(x):\n\u001B[0;32m   1302\u001B[0m     \u001B[38;5;124;03m\"\"\"Is x of a sparse matrix type?\u001B[39;00m\n\u001B[0;32m   1303\u001B[0m \n\u001B[0;32m   1304\u001B[0m \u001B[38;5;124;03m    Parameters\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1326\u001B[0m \u001B[38;5;124;03m    False\u001B[39;00m\n\u001B[0;32m   1327\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m   1328\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(x, spmatrix)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "silhouette_list = []\n",
    "for i in range(len(k_values)):\n",
    "    silhouette_list.append(silhouette_score(forest_validation_proj_scaled, forest_validation_predict[i]))\n",
    "\n",
    "plt.plot(k_values, silhouette_list)\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('silhouette')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_k_value =k_values[np.argmax(silhouette_list)]\n",
    "best_k_model = k_model_list[np.argmax(silhouette_list)]\n",
    "best_forest_validation_predict = forest_validation_predict[np.argmax(silhouette_list)]\n",
    "best_forest_validation_center = forest_validation_center[np.argmax(silhouette_list)]\n",
    "\n",
    "\n",
    "for a in range(len(forest_validation_proj_scaled[0])):\n",
    "    plt.figure()\n",
    "    plt.boxplot([forest_validation_proj_scaled[best_forest_validation_predict == b][:, a] for b in range(best_k_value)])\n",
    "    plt.title('feature ' +str(k))\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "bb119707",
   "metadata": {},
   "source": [
    "# Part 2: Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41364bb3",
   "metadata": {},
   "source": [
    "In this part of the project, you will be utilizing a US database of crime and law enforcement statistics broken down by US Census communities. The **goal** will be to create *regression models* that predict *per capita violent crimes* (the response variable `ViolentCrimesPerPop`) for a given community based on these inputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "5d0dad23",
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_column_names= ['state', 'county', 'community', 'communityname', 'fold', 'population', 'householdsize',\n",
    "                 'racepctblack', 'racePctWhite', 'racePctAsian', 'racePctHisp', 'agePct12t21', 'agePct12t29',\n",
    "                 'agePct16t24', 'agePct65up', 'numbUrban', 'pctUrban', 'medIncome', 'pctWWage', 'pctWFarmSelf',\n",
    "                 'pctWInvInc', 'pctWSocSec', 'pctWPubAsst', 'pctWRetire', 'medFamInc', 'perCapInc', 'whitePerCap',\n",
    "                 'blackPerCap', 'indianPerCap', 'AsianPerCap', 'OtherPerCap', 'HispPerCap', 'NumUnderPov', 'PctPopUnderPov',\n",
    "                 'PctLess9thGrade', 'PctNotHSGrad', 'PctBSorMore', 'PctUnemployed', 'PctEmploy', 'PctEmplManu',\n",
    "                 'PctEmplProfServ', 'PctOccupManu', 'PctOccupMgmtProf', 'MalePctDivorce', 'MalePctNevMarr',\n",
    "                 'FemalePctDiv', 'TotalPctDiv', 'PersPerFam', 'PctFam2Par', 'PctKids2Par', 'PctYoungKids2Par',\n",
    "                 'PctTeen2Par', 'PctWorkMomYoungKids', 'PctWorkMom', 'NumIlleg', 'PctIlleg', 'NumImmig', 'PctImmigRecent',\n",
    "                 'PctImmigRec5', 'PctImmigRec8', 'PctImmigRec10', 'PctRecentImmig', 'PctRecImmig5', 'PctRecImmig8',\n",
    "                 'PctRecImmig10', 'PctSpeakEnglOnly', 'PctNotSpeakEnglWell', 'PctLargHouseFam', 'PctLargHouseOccup',\n",
    "                 'PersPerOccupHous', 'PersPerOwnOccHous', 'PersPerRentOccHous', 'PctPersOwnOccup', 'PctPersDenseHous',\n",
    "                 'PctHousLess3BR', 'MedNumBR', 'HousVacant', 'PctHousOccup', 'PctHousOwnOcc', 'PctVacantBoarded',\n",
    "                 'PctVacMore6Mos', 'MedYrHousBuilt', 'PctHousNoPhone', 'PctWOFullPlumb', 'OwnOccLowQuart', 'OwnOccMedVal',\n",
    "                 'OwnOccHiQuart', 'RentLowQ', 'RentMedian', 'RentHighQ', 'MedRent', 'MedRentPctHousInc', 'MedOwnCostPctInc',\n",
    "                 'MedOwnCostPctIncNoMtg', 'NumInShelters', 'NumStreet', 'PctForeignBorn', 'PctBornSameState', 'PctSameHouse85',\n",
    "                 'PctSameCity85', 'PctSameState85', 'LemasSwornFT', 'LemasSwFTPerPop', 'LemasSwFTFieldOps',\n",
    "                 'LemasSwFTFieldPerPop', 'LemasTotalReq', 'LemasTotReqPerPop', 'PolicReqPerOffic',\n",
    "                 'PolicPerPop', 'RacialMatchCommPol', 'PctPolicWhite', 'PctPolicBlack', 'PctPolicHisp',\n",
    "                 'PctPolicAsian', 'PctPolicMinor', 'OfficAssgnDrugUnits', 'NumKindsDrugsSeiz', 'PolicAveOTWorked',\n",
    "                 'LandArea', 'PopDens', 'PctUsePubTrans', 'PolicCars', 'PolicOperBudg', 'LemasPctPolicOnPatr',\n",
    "                 'LemasGangUnitDeploy', 'LemasPctOfficDrugUn', 'PolicBudgPerPop', 'ViolentCrimesPerPop']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ccb673a",
   "metadata": {},
   "source": [
    "## 2.1 Load Data\n",
    "Set the variable `CRIME_FILE` to the **full path** to the forest cover dataset (**crime.csv**) on your system. Load the file into a dataframe (you may initialize the column names using the header list `crime_column_names`), then:\n",
    "1. Determine the number and types of features.\n",
    "2. Perform a **ShuffleSplit** of the data into training/validation/test sets, 60%/20%/20%. \n",
    "3. Split the **non-test data** (*training* + *validation* data) into **5 folds** for cross-validation purposes.\n",
    "4. Perform any necessary preprocessing on dataset. This may include:\n",
    "  * determining if any features should be dropped;\n",
    "  * handling missing data, through imputation and/or complete case analysis. If you **perform imputation on numerical values**, please use **median** imputation.\n",
    "\n",
    "**Please note!** The Scikit-learn function `SimpleImputer` does not work as expected when the feature to impute is numerical but the missing values are not. One way to solve this is to first replace the missing values with NaN values (e.g., `np.nan`) using the Pandas Dataframe method `replace` [(documentation)](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.replace.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [
    {
     "data": {
      "text/plain": "             state         fold   population  householdsize  racepctblack  \\\ncount  1994.000000  1994.000000  1994.000000    1994.000000   1994.000000   \nmean     28.683551     5.493982     0.057593       0.463395      0.179629   \nstd      16.397553     2.873694     0.126906       0.163717      0.253442   \nmin       1.000000     1.000000     0.000000       0.000000      0.000000   \n25%      12.000000     3.000000     0.010000       0.350000      0.020000   \n50%      34.000000     5.000000     0.020000       0.440000      0.060000   \n75%      42.000000     8.000000     0.050000       0.540000      0.230000   \nmax      56.000000    10.000000     1.000000       1.000000      1.000000   \n\n       racePctWhite  racePctAsian  racePctHisp  agePct12t21  agePct12t29  ...  \\\ncount   1994.000000   1994.000000  1994.000000  1994.000000  1994.000000  ...   \nmean       0.753716      0.153681     0.144022     0.424218     0.493867  ...   \nstd        0.244039      0.208877     0.232492     0.155196     0.143564  ...   \nmin        0.000000      0.000000     0.000000     0.000000     0.000000  ...   \n25%        0.630000      0.040000     0.010000     0.340000     0.410000  ...   \n50%        0.850000      0.070000     0.040000     0.400000     0.480000  ...   \n75%        0.940000      0.170000     0.160000     0.470000     0.540000  ...   \nmax        1.000000      1.000000     1.000000     1.000000     1.000000  ...   \n\n       PctForeignBorn  PctBornSameState  PctSameHouse85  PctSameCity85  \\\ncount     1994.000000       1994.000000     1994.000000    1994.000000   \nmean         0.215552          0.608892        0.535050       0.626424   \nstd          0.231134          0.204329        0.181352       0.200521   \nmin          0.000000          0.000000        0.000000       0.000000   \n25%          0.060000          0.470000        0.420000       0.520000   \n50%          0.130000          0.630000        0.540000       0.670000   \n75%          0.280000          0.777500        0.660000       0.770000   \nmax          1.000000          1.000000        1.000000       1.000000   \n\n       PctSameState85     LandArea      PopDens  PctUsePubTrans  \\\ncount     1994.000000  1994.000000  1994.000000     1994.000000   \nmean         0.651530     0.065231     0.232854        0.161685   \nstd          0.198221     0.109459     0.203092        0.229055   \nmin          0.000000     0.000000     0.000000        0.000000   \n25%          0.560000     0.020000     0.100000        0.020000   \n50%          0.700000     0.040000     0.170000        0.070000   \n75%          0.790000     0.070000     0.280000        0.190000   \nmax          1.000000     1.000000     1.000000        1.000000   \n\n       LemasPctOfficDrugUn  ViolentCrimesPerPop  \ncount          1994.000000          1994.000000  \nmean              0.094052             0.237979  \nstd               0.240328             0.232985  \nmin               0.000000             0.000000  \n25%               0.000000             0.070000  \n50%               0.000000             0.150000  \n75%               0.000000             0.330000  \nmax               1.000000             1.000000  \n\n[8 rows x 102 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>state</th>\n      <th>fold</th>\n      <th>population</th>\n      <th>householdsize</th>\n      <th>racepctblack</th>\n      <th>racePctWhite</th>\n      <th>racePctAsian</th>\n      <th>racePctHisp</th>\n      <th>agePct12t21</th>\n      <th>agePct12t29</th>\n      <th>...</th>\n      <th>PctForeignBorn</th>\n      <th>PctBornSameState</th>\n      <th>PctSameHouse85</th>\n      <th>PctSameCity85</th>\n      <th>PctSameState85</th>\n      <th>LandArea</th>\n      <th>PopDens</th>\n      <th>PctUsePubTrans</th>\n      <th>LemasPctOfficDrugUn</th>\n      <th>ViolentCrimesPerPop</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1994.000000</td>\n      <td>1994.000000</td>\n      <td>1994.000000</td>\n      <td>1994.000000</td>\n      <td>1994.000000</td>\n      <td>1994.000000</td>\n      <td>1994.000000</td>\n      <td>1994.000000</td>\n      <td>1994.000000</td>\n      <td>1994.000000</td>\n      <td>...</td>\n      <td>1994.000000</td>\n      <td>1994.000000</td>\n      <td>1994.000000</td>\n      <td>1994.000000</td>\n      <td>1994.000000</td>\n      <td>1994.000000</td>\n      <td>1994.000000</td>\n      <td>1994.000000</td>\n      <td>1994.000000</td>\n      <td>1994.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>28.683551</td>\n      <td>5.493982</td>\n      <td>0.057593</td>\n      <td>0.463395</td>\n      <td>0.179629</td>\n      <td>0.753716</td>\n      <td>0.153681</td>\n      <td>0.144022</td>\n      <td>0.424218</td>\n      <td>0.493867</td>\n      <td>...</td>\n      <td>0.215552</td>\n      <td>0.608892</td>\n      <td>0.535050</td>\n      <td>0.626424</td>\n      <td>0.651530</td>\n      <td>0.065231</td>\n      <td>0.232854</td>\n      <td>0.161685</td>\n      <td>0.094052</td>\n      <td>0.237979</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>16.397553</td>\n      <td>2.873694</td>\n      <td>0.126906</td>\n      <td>0.163717</td>\n      <td>0.253442</td>\n      <td>0.244039</td>\n      <td>0.208877</td>\n      <td>0.232492</td>\n      <td>0.155196</td>\n      <td>0.143564</td>\n      <td>...</td>\n      <td>0.231134</td>\n      <td>0.204329</td>\n      <td>0.181352</td>\n      <td>0.200521</td>\n      <td>0.198221</td>\n      <td>0.109459</td>\n      <td>0.203092</td>\n      <td>0.229055</td>\n      <td>0.240328</td>\n      <td>0.232985</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>12.000000</td>\n      <td>3.000000</td>\n      <td>0.010000</td>\n      <td>0.350000</td>\n      <td>0.020000</td>\n      <td>0.630000</td>\n      <td>0.040000</td>\n      <td>0.010000</td>\n      <td>0.340000</td>\n      <td>0.410000</td>\n      <td>...</td>\n      <td>0.060000</td>\n      <td>0.470000</td>\n      <td>0.420000</td>\n      <td>0.520000</td>\n      <td>0.560000</td>\n      <td>0.020000</td>\n      <td>0.100000</td>\n      <td>0.020000</td>\n      <td>0.000000</td>\n      <td>0.070000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>34.000000</td>\n      <td>5.000000</td>\n      <td>0.020000</td>\n      <td>0.440000</td>\n      <td>0.060000</td>\n      <td>0.850000</td>\n      <td>0.070000</td>\n      <td>0.040000</td>\n      <td>0.400000</td>\n      <td>0.480000</td>\n      <td>...</td>\n      <td>0.130000</td>\n      <td>0.630000</td>\n      <td>0.540000</td>\n      <td>0.670000</td>\n      <td>0.700000</td>\n      <td>0.040000</td>\n      <td>0.170000</td>\n      <td>0.070000</td>\n      <td>0.000000</td>\n      <td>0.150000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>42.000000</td>\n      <td>8.000000</td>\n      <td>0.050000</td>\n      <td>0.540000</td>\n      <td>0.230000</td>\n      <td>0.940000</td>\n      <td>0.170000</td>\n      <td>0.160000</td>\n      <td>0.470000</td>\n      <td>0.540000</td>\n      <td>...</td>\n      <td>0.280000</td>\n      <td>0.777500</td>\n      <td>0.660000</td>\n      <td>0.770000</td>\n      <td>0.790000</td>\n      <td>0.070000</td>\n      <td>0.280000</td>\n      <td>0.190000</td>\n      <td>0.000000</td>\n      <td>0.330000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>56.000000</td>\n      <td>10.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 102 columns</p>\n</div>"
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "CRIME_FILE=\"UTF-8_crime.csv\"\n",
    "crime_df = pd.read_csv(CRIME_FILE, header=None, names=crime_column_names)\n",
    "crime_df.describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Determine the number and types of features."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "state                    int64\n",
      "county                  object\n",
      "community               object\n",
      "communityname           object\n",
      "fold                     int64\n",
      "                        ...   \n",
      "LemasPctPolicOnPatr     object\n",
      "LemasGangUnitDeploy     object\n",
      "LemasPctOfficDrugUn    float64\n",
      "PolicBudgPerPop         object\n",
      "ViolentCrimesPerPop    float64\n",
      "Length: 128, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# determine the number of features\n",
    "print(len(crime_df.columns))\n",
    "\n",
    "# determine the data types of the features\n",
    "print(crime_df.dtypes)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "4. Perform any necessary preprocessing on dataset. This may include:\n",
    "  * determining if any features should be dropped;\n",
    "  * handling missing data, through imputation and/or complete case analysis. If you **perform imputation on numerical values**, please use **median** imputation."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "outputs": [
    {
     "data": {
      "text/plain": "state                  0\ncounty                 0\ncommunity              0\nfold                   0\npopulation             0\n                      ..\nLemasPctPolicOnPatr    0\nLemasGangUnitDeploy    0\nLemasPctOfficDrugUn    0\nPolicBudgPerPop        0\nViolentCrimesPerPop    0\nLength: 127, dtype: int64"
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "crime_df.drop(columns=['communityname'],inplace=True)\n",
    "crime_df.replace('?', np.nan, inplace= True)\n",
    "crime_df.fillna(crime_df.median(),inplace=True)\n",
    "crime_df.isnull().sum()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. Perform a **ShuffleSplit** of the data into training/validation/test sets, 60%/20%/20%.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "# define the features and the outcome\n",
    "feature_cols = [col for col in crime_df.columns if col != 'ViolentCrimesPerPop']\n",
    "X = crime_df[feature_cols]\n",
    "y = crime_df['ViolentCrimesPerPop']\n",
    "\n",
    "# define the train, test, and validation sets\n",
    "num_samples = len(crime_df)\n",
    "num_train = int(0.6 * num_samples)\n",
    "num_test = int(0.2 * num_samples)\n",
    "num_validation = num_samples - num_train - num_test\n",
    "\n",
    "train_validation_idx, test_idx = list(ShuffleSplit(n_splits=1, test_size=num_test, train_size=num_train+num_validation, random_state=23508893).split(X))[0]\n",
    "train_idx, validation_idx = list(ShuffleSplit(n_splits=1, test_size=num_validation, train_size=num_train, random_state=23508893).split(X))[0]\n",
    "\n",
    "# define the train, validation, and test sets\n",
    "X_train = X.iloc[train_idx]\n",
    "y_train = y.iloc[train_idx]\n",
    "X_validation = X.iloc[validation_idx]\n",
    "y_validation = y.iloc[validation_idx]\n",
    "X_test = X.iloc[test_idx]\n",
    "y_test = y.iloc[test_idx]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "3. Split the **non-test data** (*training* + *validation* data) into **5 folds** for cross-validation purposes."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# define the k-fold cross-validation sets\n",
    "X_train_cv, y_train_cv = [], []\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=23508893)\n",
    "for train_idx, val_idx in cv.split(X_train):\n",
    "    X_train_cv.append(X_train.iloc[train_idx])\n",
    "    y_train_cv.append(y_train.iloc[train_idx])\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "outputs": [],
   "source": [
    "#peformance metric functions\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error,r2_score\n",
    "import numpy as np\n",
    "\n",
    "#A list of keys for the dictionary returned by p1_metrics\n",
    "metric_keys = ['mse','mae','r2']\n",
    "\n",
    "def p2_metrics(y_true,y_pred,negation=False):\n",
    "    if negation:\n",
    "        sign = -1\n",
    "    else:\n",
    "        sign = 1\n",
    "    return {\n",
    "        'mse': sign*mean_squared_error(y_true,y_pred),\n",
    "        'mae': sign*mean_absolute_error(y_true,y_pred),\n",
    "        'r2': sign*r2_score(y_true,y_pred)}\n",
    "\n",
    "#This wrapper can be used to return multiple performance metrics during cross-validation\n",
    "def p2_metrics_scorer(clf,X,y_true):\n",
    "    y_pred=clf.predict(X)\n",
    "    return p2_metrics(y_true,y_pred,negation=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.2 Linear Regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Construct a linear model using Scikit-learn's `LinearRegression` method with default parameters.\n",
    "2. Report the following performance metrics on the **training and validation sets**:\n",
    "    *Mean Squared Error*, *Mean Absolute Error*, and the *Coefficient of Determination ($r^2$)*.\n",
    "\n",
    "    You can use the function `p2_metrics` for this purpose. Is this model underfitting the data? Is so, why?\n",
    "3. Report the weights (coefficients) of the linear model and their associated features in ascending order.\n",
    "\n",
    "    Larger weights indicate that their corresponding features have more influence in the model. Moreover, negative weights correspond to variables having negative correlation with the response variable, and vice versa.\n",
    "\n",
    "    Using this interpretation, describe the most significant features and their correlation."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Construct a linear model using Scikit-learn's `LinearRegression` method with default parameters.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "outputs": [
    {
     "data": {
      "text/plain": "LinearRegression()",
      "text/html": "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# construct the linear regression model\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X_train, y_train)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Report the following performance metrics on the **training and validation sets**:\n",
    "    *Mean Squared Error*, *Mean Absolute Error*, and the *Coefficient of Determination ($r^2$)*.\n",
    "\n",
    "    You can use the function `p2_metrics` for this purpose. Is this model underfitting the data? Is so, why?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mse': 0.015284792566611765, 'mae': 0.08742863634445308, 'r2': 0.7043525199361096}\n",
      "{'mse': 0.02175752145330092, 'mae': 0.10329928637202596, 'r2': 0.593126272710371}\n"
     ]
    }
   ],
   "source": [
    "# calculate the performance metrics on the training set\n",
    "y_train_pred = linreg.predict(X_train)\n",
    "print(p2_metrics(y_train, y_train_pred))\n",
    "\n",
    "# calculate the performance metrics on the validation set\n",
    "y_validation_pred = linreg.predict(X_validation)\n",
    "print(p2_metrics(y_validation, y_validation_pred))\n",
    "\n",
    "# # print the slope and intercept of the linear regression model\n",
    "# print(linreg.coef_)\n",
    "# print(linreg.intercept_)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Yes, this model is underfitting the data. The high MSE and MAE values indicate that the model is not able to accurately predict the labels. The low $r^2$ value also indicates that the model is not able to explain the variance in the data."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "3. Report the weights (coefficients) of the linear model and their associated features in ascending order.\n",
    "\n",
    "    Larger weights indicate that their corresponding features have more influence in the model. Moreover, negative weights correspond to variables having negative correlation with the response variable, and vice versa.\n",
    "\n",
    "    Using this interpretation, describe the most significant features and their correlation."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LemasSwFTPerPop -13.57659632898163\n",
      "TotalPctDiv -1.259194135262757\n",
      "OfficAssgnDrugUnits -0.4282089120709388\n",
      "PctPersOwnOccup -0.3880102289629942\n",
      "LemasTotalReq -0.29737041565828715\n",
      "PctRecImmig10 -0.29543420580998603\n",
      "NumUnderPov -0.29264364590428293\n",
      "PctWorkMom -0.28909305959444004\n",
      "whitePerCap -0.27030744606602436\n",
      "agePct12t29 -0.24471493150524137\n",
      "PctPopUnderPov -0.22720410210812753\n",
      "pctWWage -0.2206092730804402\n",
      "PctKids2Par -0.21664537215644064\n",
      "medIncome -0.21263033172224605\n",
      "RentLowQ -0.21025401590646822\n",
      "PersPerRentOccHous -0.20577431944000932\n",
      "PersPerFam -0.20365922905810557\n",
      "PctLargHouseOccup -0.18472078038333742\n",
      "NumImmig -0.16951322892570275\n",
      "LemasPctPolicOnPatr -0.16465740295823655\n",
      "PolicBudgPerPop -0.16194218021104437\n",
      "PctImmigRec8 -0.16035222527938925\n",
      "agePct16t24 -0.1557441316507042\n",
      "pctWInvInc -0.13780577396656946\n",
      "PctLess9thGrade -0.13330724314692344\n",
      "PctNotSpeakEnglWell -0.12775515188721354\n",
      "racePctWhite -0.11892887906706551\n",
      "PersPerOwnOccHous -0.0946388146237177\n",
      "OwnOccLowQuart -0.0933279663392812\n",
      "householdsize -0.0852244405691378\n",
      "NumIlleg -0.08518633145674064\n",
      "population -0.08472238274534047\n",
      "PctPolicWhite -0.08366029394887678\n",
      "PctYoungKids2Par -0.08170144010368717\n",
      "RentMedian -0.078934420409037\n",
      "MedOwnCostPctIncNoMtg -0.07866186102981536\n",
      "PctTeen2Par -0.07119050902739478\n",
      "PctVacMore6Mos -0.0711726279698128\n",
      "blackPerCap -0.06598354047096282\n",
      "PctHousOccup -0.06543433720683473\n",
      "pctWRetire -0.06483274293671444\n",
      "PctRecImmig5 -0.05780304532690425\n",
      "PctEmplManu -0.0507927385464228\n",
      "PctUsePubTrans -0.048531928373319544\n",
      "PctWOFullPlumb -0.0394792897211437\n",
      "RacialMatchCommPol -0.03927687190565033\n",
      "indianPerCap -0.029976939624444525\n",
      "MedOwnCostPctInc -0.028505310241855708\n",
      "OwnOccMedVal -0.026499291322105892\n",
      "agePct65up -0.02486818576419267\n",
      "PctRecentImmig -0.02097113660010111\n",
      "PolicAveOTWorked -0.02029443049952393\n",
      "perCapInc -0.01685171639319903\n",
      "LandArea -0.015839221910615986\n",
      "MedYrHousBuilt -0.01104173947198637\n",
      "MedNumBR -0.009340419409359313\n",
      "PctBornSameState -0.005171248544492885\n",
      "PctPolicAsian -0.003457093252604935\n",
      "OwnOccHiQuart -0.0027869275551898054\n",
      "fold -0.0013835647543753438\n",
      "PctSameCity85 -0.0008645703848523534\n",
      "state -0.0006765100762633645\n",
      "county -0.00011736903523109203\n",
      "community -3.8209135563111937e-07\n",
      "RentHighQ 0.0009830860018178803\n",
      "PctPolicBlack 0.004295484699728597\n",
      "LemasPctOfficDrugUn 0.005592735714137695\n",
      "racePctAsian 0.006732204538179479\n",
      "PctSameHouse85 0.007239485268563467\n",
      "PctImmigRec5 0.009521217866536591\n",
      "PopDens 0.010774028824331289\n",
      "AsianPerCap 0.01134152979979973\n",
      "LemasTotReqPerPop 0.014171114855217264\n",
      "HispPerCap 0.015027972510536362\n",
      "PctPolicMinor 0.02254495492488725\n",
      "PctSameState85 0.02416182213489986\n",
      "PctOccupMgmtProf 0.02897536137517337\n",
      "PctEmplProfServ 0.029474027554012155\n",
      "PctImmigRecent 0.03387562385135648\n",
      "LemasGangUnitDeploy 0.0342998721154501\n",
      "pctWFarmSelf 0.03679108772789236\n",
      "PctHousLess3BR 0.037578928671687335\n",
      "pctWPubAsst 0.03860989315338406\n",
      "pctUrban 0.03884669984415967\n",
      "MedRentPctHousInc 0.043266545206184795\n",
      "OtherPerCap 0.04333494530554445\n",
      "PctSpeakEnglOnly 0.04510356953664124\n",
      "PctHousNoPhone 0.04615084663411728\n",
      "PctVacantBoarded 0.05229869844290563\n",
      "PctPolicHisp 0.054601779920680216\n",
      "PctUnemployed 0.056357784311605374\n",
      "racePctHisp 0.05993004218944642\n",
      "PctOccupManu 0.0613108340632908\n",
      "NumKindsDrugsSeiz 0.06856863906640269\n",
      "PctForeignBorn 0.07833126705051152\n",
      "PctImmigRec10 0.09457365172165617\n",
      "PctBSorMore 0.09517208976013355\n",
      "PctLargHouseFam 0.0967953508364473\n",
      "NumInShelters 0.1092347356846721\n",
      "PctIlleg 0.11116092168577801\n",
      "pctWSocSec 0.1158558092752779\n",
      "PctFam2Par 0.13729692013664083\n",
      "PolicReqPerOffic 0.1389769780035347\n",
      "PctWorkMomYoungKids 0.14002684249717123\n",
      "NumStreet 0.15394997808490665\n",
      "PctNotHSGrad 0.17019349696782374\n",
      "MalePctNevMarr 0.17967674537748576\n",
      "agePct12t21 0.19053467019947962\n",
      "racepctblack 0.2007791448682172\n",
      "PolicCars 0.205955877292134\n",
      "HousVacant 0.20894189868661212\n",
      "PctHousOwnOcc 0.21962035117898415\n",
      "numbUrban 0.2327255920233112\n",
      "PctPersDenseHous 0.23837670180838816\n",
      "PctEmploy 0.29666701565625164\n",
      "MedRent 0.36252486937239986\n",
      "PctRecImmig8 0.3953275956463116\n",
      "medFamInc 0.42032327768000044\n",
      "PersPerOccupHous 0.5273031751013335\n",
      "FemalePctDiv 0.5699827162024416\n",
      "PolicOperBudg 0.6645167182769349\n",
      "MalePctDivorce 0.7078224644702226\n",
      "LemasSwornFT 1.0962568752244597\n",
      "LemasSwFTFieldPerPop 1.3850906706585262\n",
      "LemasSwFTFieldOps 1.426041262525357\n",
      "PolicPerPop 12.37304043206996\n"
     ]
    }
   ],
   "source": [
    "feature_cols=list(crime_df.drop(columns=['ViolentCrimesPerPop']).columns)\n",
    "# create a list of tuples containing the feature names and their weights\n",
    "feature_weights =sorted(list(zip(feature_cols, linreg.coef_)), key=lambda t: t[1])\n",
    "\n",
    "# print the feature names and their weights\n",
    "for feature, weight in feature_weights:\n",
    "    print(feature, weight)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The most significant features are 'medFamInc ', 'PctRecImmig8 ', 'PolicOperBudg ', 'PersPerOccupHous ' These features have the largest weights in the linear regression model."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.3 Linear Regression and PCA"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Perform principal component analysis on the **training data**. You may use Scikit-learn's `PCA` function for this, which **automatically centers** the data prior to PCA. Using PCA, *choose the number of components* for which the total explained variance is $\\ge 99\\%$, and report this.\n",
    "2. After determining the correct number of components, apply the PCA transformation to the **validation** and **test** sets.\n",
    "3. Create another model via `LinearRegression` but using the data transformed by PCA\n",
    "Construct a linear model using Scikit-learn's `LinearRegression` method with default parameters.\n",
    "4. Report the same performance metrics as in 2.2 on the **validation set**. How does the model's performance compare to that of the model in 2.2?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mse': 0.051564264682491166, 'mae': 0.17219681515084923, 'r2': 0.002613555382691257}\n",
      "{'mse': 0.05386561976616491, 'mae': 0.17791650306568713, 'r2': -0.007307083854461327}\n",
      "{'mse': 0.0539450987861387, 'mae': 0.17783302133745826, 'r2': -0.007642662680338752}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tanzi\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\linear_model\\_base.py:141: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# construct the PCA model\n",
    "pca = PCA(n_components=0.99, random_state=23508893)\n",
    "\n",
    "# fit the PCA model on the train set\n",
    "pca.fit(X_train)\n",
    "# transform the train, validation, and test sets\n",
    "X_train_pca = pca.transform(X_train)\n",
    "X_validation_pca = pca.transform(X_validation)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "# construct the linear regression model\n",
    "linreg = LinearRegression(normalize=True)\n",
    "\n",
    "# fit the linear regression model on the train set\n",
    "linreg.fit(X_train_pca, y_train)\n",
    "\n",
    "# calculate the performance metrics on the train set\n",
    "y_train_pred = linreg.predict(X_train_pca)\n",
    "print(p2_metrics(y_train, y_train_pred))\n",
    "\n",
    "# calculate the performance metrics on the validation set\n",
    "y_validation_pred = linreg.predict(X_validation_pca)\n",
    "print(p2_metrics(y_validation, y_validation_pred))\n",
    "\n",
    "# calculate the performance metrics on the test set\n",
    "y_test_pred = linreg.predict(X_test_pca)\n",
    "print(p2_metrics(y_test, y_test_pred))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Before PCA, the linear regression model had an $r^2$ value of 0.730 on the training set and 0.597 on the validation set. After PCA, the $r^2$ values decreased to 0.001 on the training set and -0.022 on the validation set. This indicates that the PCA model is not able to explain the variance in the data as well as the linear regression model."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.4 LASSO"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Utilizing *cross-validation* you will Construct an $\\ell_1$-regularized linear model using Scikit-learn's `LASSO`:\n",
    "1. Using `GridSearchCV`, determine the best choice of the hyperparameter $\\alpha$ out of values in the list `alphas` below.\n",
    "2. Report the time required to perform cross-validation via `GridSearchCV`. Report the mean and standard deviation of the performance metrics for the best performing model along with its associated hyperparameter. You may use the function `collate_ht_results` for this purpose.\n",
    "3. Report the weights (coefficients) of the LASSO model and their associated features in ascending order. Note that LASSO attempts to set as many weights to zero in order to create a more parsimonious model while still maintaining regression performance. How many weights are non-zero?\n",
    "\n",
    "### Please Read!\n",
    "There are a few parameters for the `GridSearchCV` and `RandomizedSearchCV` functions that should be set:\n",
    "- `scoring` - This controls the strategy to evaluate the performance of the cross-validated model on the test set, set it to `p2_metrics_scorer`.\n",
    "- `refit` - This will refit an estimator using the best found parameters on the whole dataset, set it to `\"mse\"`\n",
    "- `cv` - This will enable you to reuse your CV splits created in Part 2.1\n",
    "    `n_jobs` - Number of jobs to run in parallel, if you have more than one core on your device (you should), set this to as many as you'd like to use, or to `-1` if you want to use all available cores.\n",
    "- `return_train_score` - Setting this to `False` will reduce computational time."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "outputs": [],
   "source": [
    "alphas = 10**np.linspace(1,-3,50)*0.5"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "outputs": [],
   "source": [
    "#Summarizes model performance results produced during hyperparameter tuning\n",
    "def collate_ht_results(ht_results,metric_keys=metric_keys,display=True):\n",
    "    ht_stats=dict()\n",
    "    for metric in metric_keys:\n",
    "        ht_stats[metric+\"_mean\"] = ht_results.cv_results_[\"mean_test_\"+metric][ht_results.best_index_]\n",
    "        ht_stats[metric+\"_std\"] = metric_std = ht_results.cv_results_[\"std_test_\"+metric][ht_results.best_index_]\n",
    "        if display:\n",
    "            print(\"test_\"+metric,ht_stats[metric+\"_mean\"],\"(\"+str(ht_stats[metric+\"_std\"])+\")\")\n",
    "    return ht_stats"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time required for cross-validation:  4.574033737182617 seconds\n",
      "test_mse -0.018909975602130872 (0.00183485762658173)\n",
      "test_mae -0.09461234037510413 (0.004826414606838783)\n",
      "test_r2 -0.6305359451213535 (0.03484320614195056)\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'mse_mean': -0.018909975602130872,\n 'mse_std': 0.00183485762658173,\n 'mae_mean': -0.09461234037510413,\n 'mae_std': 0.004826414606838783,\n 'r2_mean': -0.6305359451213535,\n 'r2_std': 0.03484320614195056}"
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import required libraries\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import time\n",
    "\n",
    "# define the parameter grid\n",
    "param_grid = {\n",
    "    'alpha': alphas\n",
    "}\n",
    "\n",
    "# instantiate a Lasso regression model\n",
    "lasso_model = Lasso()\n",
    "\n",
    "# create a cross-validation object\n",
    "cv_object = KFold(n_splits=cv.n_splits, shuffle=True)\n",
    "\n",
    "# set up the grid search object\n",
    "grid_search = GridSearchCV(lasso_model, param_grid=param_grid, scoring=p2_metrics_scorer,\n",
    "                           refit=\"mse\", cv=cv_object, n_jobs=-1, return_train_score=False)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# fit the grid search\n",
    "grid_search.fit(X_train, y_train)\n",
    "end = time.time()\n",
    "\n",
    "# calculate the time required for cross-validation\n",
    "cv_time = end - start\n",
    "\n",
    "# print the time required for cross-validation\n",
    "print(\"Time required for cross-validation: \", cv_time, \"seconds\")\n",
    "\n",
    "# print the mean and standard deviation for each performance metric\n",
    "collate_ht_results(grid_search)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PctKids2Par -0.14140947810183901\n",
      "racePctWhite -0.12672882145541495\n",
      "PctYoungKids2Par -0.06582648866589637\n",
      "PctWorkMom -0.04513930683459802\n",
      "PctHousOccup -0.04108316758609205\n",
      "pctWWage -0.020723487907746745\n",
      "MedNumBR -0.012489849521359014\n",
      "PctBSorMore -0.009835342199270979\n",
      "agePct16t24 -0.006118944503484232\n",
      "PctImmigRec5 -0.005658453443103123\n",
      "MedOwnCostPctIncNoMtg -0.0037260390104209827\n",
      "fold -0.0017182343480064402\n",
      "state -0.001271663502380025\n",
      "county -8.509220855882153e-05\n",
      "community -4.1009710100071634e-07\n",
      "population 0.0\n",
      "householdsize -0.0\n",
      "racePctAsian -0.0\n",
      "racePctHisp 0.0\n",
      "agePct12t21 -0.0\n",
      "agePct12t29 -0.0\n",
      "agePct65up 0.0\n",
      "numbUrban 0.0\n",
      "medIncome -0.0\n",
      "pctWFarmSelf -0.0\n",
      "pctWInvInc -0.0\n",
      "pctWSocSec 0.0\n",
      "pctWPubAsst 0.0\n",
      "pctWRetire 0.0\n",
      "medFamInc -0.0\n",
      "perCapInc -0.0\n",
      "whitePerCap -0.0\n",
      "blackPerCap -0.0\n",
      "indianPerCap -0.0\n",
      "AsianPerCap 0.0\n",
      "OtherPerCap 0.0\n",
      "HispPerCap -0.0\n",
      "NumUnderPov 0.0\n",
      "PctPopUnderPov -0.0\n",
      "PctLess9thGrade 0.0\n",
      "PctNotHSGrad 0.0\n",
      "PctUnemployed 0.0\n",
      "PctEmploy -0.0\n",
      "PctEmplManu -0.0\n",
      "PctEmplProfServ -0.0\n",
      "PctOccupManu 0.0\n",
      "PctOccupMgmtProf -0.0\n",
      "MalePctNevMarr -0.0\n",
      "FemalePctDiv 0.0\n",
      "TotalPctDiv 0.0\n",
      "PersPerFam 0.0\n",
      "PctFam2Par -0.0\n",
      "PctTeen2Par -0.0\n",
      "PctWorkMomYoungKids -0.0\n",
      "NumIlleg 0.0\n",
      "NumImmig 0.0\n",
      "PctImmigRecent -0.0\n",
      "PctImmigRec8 -0.0\n",
      "PctImmigRec10 -0.0\n",
      "PctRecentImmig 0.0\n",
      "PctRecImmig5 0.0\n",
      "PctRecImmig8 0.0\n",
      "PctRecImmig10 0.0\n",
      "PctSpeakEnglOnly -0.0\n",
      "PctNotSpeakEnglWell 0.0\n",
      "PctLargHouseFam 0.0\n",
      "PctLargHouseOccup 0.0\n",
      "PersPerOccupHous 0.0\n",
      "PersPerOwnOccHous -0.0\n",
      "PersPerRentOccHous 0.0\n",
      "PctPersOwnOccup -0.0\n",
      "PctHousLess3BR 0.0\n",
      "PctHousOwnOcc -0.0\n",
      "PctVacMore6Mos -0.0\n",
      "MedYrHousBuilt -0.0\n",
      "PctHousNoPhone 0.0\n",
      "PctWOFullPlumb -0.0\n",
      "OwnOccLowQuart -0.0\n",
      "OwnOccMedVal -0.0\n",
      "OwnOccHiQuart -0.0\n",
      "RentLowQ -0.0\n",
      "RentMedian -0.0\n",
      "RentHighQ -0.0\n",
      "MedRent -0.0\n",
      "MedRentPctHousInc 0.0\n",
      "MedOwnCostPctInc -0.0\n",
      "NumInShelters 0.0\n",
      "NumStreet 0.0\n",
      "PctForeignBorn 0.0\n",
      "PctBornSameState -0.0\n",
      "PctSameHouse85 0.0\n",
      "PctSameCity85 0.0\n",
      "PctSameState85 0.0\n",
      "LemasSwornFT 0.0\n",
      "LemasSwFTPerPop 0.0\n",
      "LemasSwFTFieldOps -0.0\n",
      "LemasSwFTFieldPerPop 0.0\n",
      "LemasTotalReq 0.0\n",
      "LemasTotReqPerPop 0.0\n",
      "PolicReqPerOffic 0.0\n",
      "PolicPerPop 0.0\n",
      "RacialMatchCommPol -0.0\n",
      "PctPolicWhite -0.0\n",
      "PctPolicBlack 0.0\n",
      "PctPolicHisp 0.0\n",
      "PctPolicAsian 0.0\n",
      "PctPolicMinor 0.0\n",
      "OfficAssgnDrugUnits 0.0\n",
      "NumKindsDrugsSeiz 0.0\n",
      "PolicAveOTWorked 0.0\n",
      "LandArea 0.0\n",
      "PopDens 0.0\n",
      "PctUsePubTrans -0.0\n",
      "PolicCars 0.0\n",
      "PolicOperBudg 0.0\n",
      "LemasPctPolicOnPatr -0.0\n",
      "LemasGangUnitDeploy 0.0\n",
      "PolicBudgPerPop 0.0\n",
      "LemasPctOfficDrugUn 0.00020497592438174398\n",
      "PctVacantBoarded 0.035893541933442526\n",
      "pctUrban 0.039601184213397665\n",
      "MalePctDivorce 0.08533302085960778\n",
      "PctPersDenseHous 0.10274602522151685\n",
      "racepctblack 0.11787896102169697\n",
      "HousVacant 0.14605939115711566\n",
      "PctIlleg 0.1954340146935659\n",
      "Non Zero Weights: 23\n"
     ]
    }
   ],
   "source": [
    "# coefficients of the LASSO model\n",
    "coefficients = grid_search.best_estimator_.coef_\n",
    "feature_cols=list(crime_df.drop(columns=['ViolentCrimesPerPop']).columns)\n",
    "# create a list of tuples containing the feature names and their weights\n",
    "feature_weights = sorted(list(zip(feature_cols, coefficients)), key=lambda t: t[1])\n",
    "\n",
    "# print the feature names and their weights\n",
    "for feature, weight in feature_weights:\n",
    "    print(feature, weight)\n",
    "\n",
    "\n",
    "# number of non-zero weights\n",
    "num_non_zero_weights = sum(coefficients != 0)\n",
    "print(\"Non Zero Weights: {}\".format(num_non_zero_weights))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.5 Multilayer Perceptron (MLP)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Utilizing *cross-validation* you will construct an MLP regression model using Scikit-learn's `MLPRegressor`:\n",
    "1. Using `GridSearchCV`, determine the best choice of hyperparameters out of the following possible values:\n",
    "- *Number of hidden layers*: [1, 2, 3]\n",
    "- *Number of neurons per layer*: [10, 20, 50]\n",
    "- *Learning rate*: [1e-5, 1e-4, 0.001, 0.01, 0.1, 0.5, 1, 5, 10, 50, 100]\n",
    "\n",
    "2. Report the time required to perform cross-validation via `GridSearchCV`. Report the mean and standard deviation of the performance metrics for the best performing model along with its associated hyperparameter. You may use the function `collate_ht_results` for this purpose.\n",
    "\n",
    "\n",
    "### Please Read!\n",
    "In addition to utilizing the same `GridSearchCV` parameters as in 2.5, the `MLPRegressor` function should have the following parameters set:\n",
    "- `max_iter` -  This controls the maximum number of rounds of backpropagation/gradient descent; set it to 10,000.\n",
    "- `early_stopping` - This will reserve a portion of the training data tha can be used to evaluate convergence progress in order to stop training early; set it to `True`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "# define the grid search parameters\n",
    "hidden_layer_sizes = [(l,) * n for l in [10, 20, 50] for n in [1, 2, 3]]\n",
    "learning_rate = [1e-5, 1e-4, 0.001, 0.01, 0.1, 0.5, 1, 5, 10, 50, 100]\n",
    "# define the grid search parameters\n",
    "\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': hidden_layer_sizes,\n",
    "    'learning_rate': learning_rate,\n",
    "}\n",
    "\n",
    "# instantiate an MLP regression model\n",
    "mlp_model = MLPRegressor(max_iter=10000, early_stopping=True)\n",
    "\n",
    "# create a cross-validation object\n",
    "cv_object = KFold(n_splits=cv.n_splits, shuffle=True)\n",
    "\n",
    "# set up the grid search object\n",
    "grid_search = GridSearchCV(mlp_model, param_grid=param_grid, scoring=p2_metrics_scorer,\n",
    "                           refit=\"mse\", cv=cv_object, n_jobs=-1, return_train_score=False)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\nAll the 495 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n45 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\tanzi\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\tanzi\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 762, in fit\n    return self._fit(X, y, incremental=False)\n  File \"C:\\Users\\tanzi\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 385, in _fit\n    self._validate_hyperparameters()\n  File \"C:\\Users\\tanzi\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 508, in _validate_hyperparameters\n    raise ValueError(\"learning rate %s is not supported. \" % self.learning_rate)\nValueError: learning rate 1e-05 is not supported. \n\n--------------------------------------------------------------------------------\n45 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\tanzi\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\tanzi\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 762, in fit\n    return self._fit(X, y, incremental=False)\n  File \"C:\\Users\\tanzi\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 385, in _fit\n    self._validate_hyperparameters()\n  File \"C:\\Users\\tanzi\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 508, in _validate_hyperparameters\n    raise ValueError(\"learning rate %s is not supported. \" % self.learning_rate)\nValueError: learning rate 0.0001 is not supported. \n\n--------------------------------------------------------------------------------\n45 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\tanzi\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\tanzi\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 762, in fit\n    return self._fit(X, y, incremental=False)\n  File \"C:\\Users\\tanzi\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 385, in _fit\n    self._validate_hyperparameters()\n  File \"C:\\Users\\tanzi\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 508, in _validate_hyperparameters\n    raise ValueError(\"learning rate %s is not supported. \" % self.learning_rate)\nValueError: learning rate 0.001 is not supported. \n\n--------------------------------------------------------------------------------\n45 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\tanzi\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\tanzi\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 762, in fit\n    return self._fit(X, y, incremental=False)\n  File \"C:\\Users\\tanzi\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 385, in _fit\n    self._validate_hyperparameters()\n  File \"C:\\Users\\tanzi\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 508, in _validate_hyperparameters\n    raise ValueError(\"learning rate %s is not supported. \" % self.learning_rate)\nValueError: learning rate 0.01 is not supported. \n\n--------------------------------------------------------------------------------\n45 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\tanzi\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\tanzi\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 762, in fit\n    return self._fit(X, y, incremental=False)\n  File \"C:\\Users\\tanzi\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 385, in _fit\n    self._validate_hyperparameters()\n  File \"C:\\Users\\tanzi\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 508, in _validate_hyperparameters\n    raise ValueError(\"learning rate %s is not supported. \" % self.learning_rate)\nValueError: learning rate 0.1 is not supported. \n\n--------------------------------------------------------------------------------\n45 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\tanzi\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\tanzi\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 762, in fit\n    return self._fit(X, y, incremental=False)\n  File \"C:\\Users\\tanzi\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 385, in _fit\n    self._validate_hyperparameters()\n  File \"C:\\Users\\tanzi\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 508, in _validate_hyperparameters\n    raise ValueError(\"learning rate %s is not supported. \" % self.learning_rate)\nValueError: learning rate 0.5 is not supported. \n\n--------------------------------------------------------------------------------\n45 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\tanzi\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\tanzi\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 762, in fit\n    return self._fit(X, y, incremental=False)\n  File \"C:\\Users\\tanzi\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 385, in _fit\n    self._validate_hyperparameters()\n  File \"C:\\Users\\tanzi\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 508, in _validate_hyperparameters\n    raise ValueError(\"learning rate %s is not supported. \" % self.learning_rate)\nValueError: learning rate 1 is not supported. \n\n--------------------------------------------------------------------------------\n45 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\tanzi\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\tanzi\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 762, in fit\n    return self._fit(X, y, incremental=False)\n  File \"C:\\Users\\tanzi\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 385, in _fit\n    self._validate_hyperparameters()\n  File \"C:\\Users\\tanzi\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 508, in _validate_hyperparameters\n    raise ValueError(\"learning rate %s is not supported. \" % self.learning_rate)\nValueError: learning rate 5 is not supported. \n\n--------------------------------------------------------------------------------\n45 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\tanzi\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\tanzi\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 762, in fit\n    return self._fit(X, y, incremental=False)\n  File \"C:\\Users\\tanzi\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 385, in _fit\n    self._validate_hyperparameters()\n  File \"C:\\Users\\tanzi\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 508, in _validate_hyperparameters\n    raise ValueError(\"learning rate %s is not supported. \" % self.learning_rate)\nValueError: learning rate 10 is not supported. \n\n--------------------------------------------------------------------------------\n45 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\tanzi\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\tanzi\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 762, in fit\n    return self._fit(X, y, incremental=False)\n  File \"C:\\Users\\tanzi\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 385, in _fit\n    self._validate_hyperparameters()\n  File \"C:\\Users\\tanzi\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 508, in _validate_hyperparameters\n    raise ValueError(\"learning rate %s is not supported. \" % self.learning_rate)\nValueError: learning rate 50 is not supported. \n\n--------------------------------------------------------------------------------\n45 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\tanzi\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\tanzi\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 762, in fit\n    return self._fit(X, y, incremental=False)\n  File \"C:\\Users\\tanzi\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 385, in _fit\n    self._validate_hyperparameters()\n  File \"C:\\Users\\tanzi\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 508, in _validate_hyperparameters\n    raise ValueError(\"learning rate %s is not supported. \" % self.learning_rate)\nValueError: learning rate 100 is not supported. \n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [147], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# fit the grid search\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;66;03m# grid_search.fit(crime_df.drop(columns=['ViolentCrimesPerPop']), crime_df['ViolentCrimesPerPop'])\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m \u001B[43mgrid_search\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:875\u001B[0m, in \u001B[0;36mBaseSearchCV.fit\u001B[1;34m(self, X, y, groups, **fit_params)\u001B[0m\n\u001B[0;32m    869\u001B[0m     results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format_results(\n\u001B[0;32m    870\u001B[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001B[0;32m    871\u001B[0m     )\n\u001B[0;32m    873\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m results\n\u001B[1;32m--> 875\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_search\u001B[49m\u001B[43m(\u001B[49m\u001B[43mevaluate_candidates\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    877\u001B[0m \u001B[38;5;66;03m# multimetric is determined here because in the case of a callable\u001B[39;00m\n\u001B[0;32m    878\u001B[0m \u001B[38;5;66;03m# self.scoring the return type is only known after calling\u001B[39;00m\n\u001B[0;32m    879\u001B[0m first_test_score \u001B[38;5;241m=\u001B[39m all_out[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_scores\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[1;32m~\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1379\u001B[0m, in \u001B[0;36mGridSearchCV._run_search\u001B[1;34m(self, evaluate_candidates)\u001B[0m\n\u001B[0;32m   1377\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_run_search\u001B[39m(\u001B[38;5;28mself\u001B[39m, evaluate_candidates):\n\u001B[0;32m   1378\u001B[0m     \u001B[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001B[39;00m\n\u001B[1;32m-> 1379\u001B[0m     \u001B[43mevaluate_candidates\u001B[49m\u001B[43m(\u001B[49m\u001B[43mParameterGrid\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparam_grid\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:852\u001B[0m, in \u001B[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001B[1;34m(candidate_params, cv, more_results)\u001B[0m\n\u001B[0;32m    845\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(out) \u001B[38;5;241m!=\u001B[39m n_candidates \u001B[38;5;241m*\u001B[39m n_splits:\n\u001B[0;32m    846\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    847\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcv.split and cv.get_n_splits returned \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    848\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124minconsistent results. Expected \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    849\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msplits, got \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(n_splits, \u001B[38;5;28mlen\u001B[39m(out) \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m n_candidates)\n\u001B[0;32m    850\u001B[0m     )\n\u001B[1;32m--> 852\u001B[0m \u001B[43m_warn_or_raise_about_fit_failures\u001B[49m\u001B[43m(\u001B[49m\u001B[43mout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43merror_score\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    854\u001B[0m \u001B[38;5;66;03m# For callable self.scoring, the return type is only know after\u001B[39;00m\n\u001B[0;32m    855\u001B[0m \u001B[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001B[39;00m\n\u001B[0;32m    856\u001B[0m \u001B[38;5;66;03m# can now be inserted with the correct key. The type checking\u001B[39;00m\n\u001B[0;32m    857\u001B[0m \u001B[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001B[39;00m\n\u001B[0;32m    858\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m callable(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscoring):\n",
      "File \u001B[1;32m~\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:367\u001B[0m, in \u001B[0;36m_warn_or_raise_about_fit_failures\u001B[1;34m(results, error_score)\u001B[0m\n\u001B[0;32m    360\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m num_failed_fits \u001B[38;5;241m==\u001B[39m num_fits:\n\u001B[0;32m    361\u001B[0m     all_fits_failed_message \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    362\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mAll the \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnum_fits\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m fits failed.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    363\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIt is very likely that your model is misconfigured.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    364\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYou can try to debug the error by setting error_score=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mraise\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    365\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBelow are more details about the failures:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mfit_errors_summary\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    366\u001B[0m     )\n\u001B[1;32m--> 367\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(all_fits_failed_message)\n\u001B[0;32m    369\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    370\u001B[0m     some_fits_failed_message \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    371\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mnum_failed_fits\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m fits failed out of a total of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnum_fits\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    372\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe score on these train-test partitions for these parameters\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    376\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBelow are more details about the failures:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mfit_errors_summary\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    377\u001B[0m     )\n",
      "\u001B[1;31mValueError\u001B[0m: \nAll the 495 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n45 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\tanzi\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\tanzi\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 762, in fit\n    return self._fit(X, y, incremental=False)\n  File \"C:\\Users\\tanzi\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 385, in _fit\n    self._validate_hyperparameters()\n  File \"C:\\Users\\tanzi\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 508, in _validate_hyperparameters\n    raise ValueError(\"learning rate %s is not supported. \" % self.learning_rate)\nValueError: learning rate 1e-05 is not supported. \n\n--------------------------------------------------------------------------------\n45 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\tanzi\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\tanzi\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 762, in fit\n    return self._fit(X, y, incremental=False)\n  File \"C:\\Users\\tanzi\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 385, in _fit\n    self._validate_hyperparameters()\n  File \"C:\\Users\\tanzi\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 508, in _validate_hyperparameters\n    raise ValueError(\"learning rate %s is not supported. \" % self.learning_rate)\nValueError: learning rate 0.0001 is not supported. \n\n--------------------------------------------------------------------------------\n45 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\tanzi\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\tanzi\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 762, in fit\n    return self._fit(X, y, incremental=False)\n  File \"C:\\Users\\tanzi\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 385, in _fit\n    self._validate_hyperparameters()\n  File \"C:\\Users\\tanzi\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 508, in _validate_hyperparameters\n    raise ValueError(\"learning rate %s is not supported. \" % self.learning_rate)\nValueError: learning rate 0.001 is not supported. \n\n--------------------------------------------------------------------------------\n45 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\tanzi\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\tanzi\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 762, in fit\n    return self._fit(X, y, incremental=False)\n  File \"C:\\Users\\tanzi\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 385, in _fit\n    self._validate_hyperparameters()\n  File \"C:\\Users\\tanzi\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 508, in _validate_hyperparameters\n    raise ValueError(\"learning rate %s is not supported. \" % self.learning_rate)\nValueError: learning rate 0.01 is not supported. \n\n--------------------------------------------------------------------------------\n45 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\tanzi\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\tanzi\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 762, in fit\n    return self._fit(X, y, incremental=False)\n  File \"C:\\Users\\tanzi\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 385, in _fit\n    self._validate_hyperparameters()\n  File \"C:\\Users\\tanzi\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 508, in _validate_hyperparameters\n    raise ValueError(\"learning rate %s is not supported. \" % self.learning_rate)\nValueError: learning rate 0.1 is not supported. \n\n--------------------------------------------------------------------------------\n45 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\tanzi\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\tanzi\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 762, in fit\n    return self._fit(X, y, incremental=False)\n  File \"C:\\Users\\tanzi\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 385, in _fit\n    self._validate_hyperparameters()\n  File \"C:\\Users\\tanzi\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 508, in _validate_hyperparameters\n    raise ValueError(\"learning rate %s is not supported. \" % self.learning_rate)\nValueError: learning rate 0.5 is not supported. \n\n--------------------------------------------------------------------------------\n45 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\tanzi\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\tanzi\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 762, in fit\n    return self._fit(X, y, incremental=False)\n  File \"C:\\Users\\tanzi\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 385, in _fit\n    self._validate_hyperparameters()\n  File \"C:\\Users\\tanzi\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 508, in _validate_hyperparameters\n    raise ValueError(\"learning rate %s is not supported. \" % self.learning_rate)\nValueError: learning rate 1 is not supported. \n\n--------------------------------------------------------------------------------\n45 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\tanzi\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\tanzi\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 762, in fit\n    return self._fit(X, y, incremental=False)\n  File \"C:\\Users\\tanzi\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 385, in _fit\n    self._validate_hyperparameters()\n  File \"C:\\Users\\tanzi\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 508, in _validate_hyperparameters\n    raise ValueError(\"learning rate %s is not supported. \" % self.learning_rate)\nValueError: learning rate 5 is not supported. \n\n--------------------------------------------------------------------------------\n45 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\tanzi\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\tanzi\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 762, in fit\n    return self._fit(X, y, incremental=False)\n  File \"C:\\Users\\tanzi\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 385, in _fit\n    self._validate_hyperparameters()\n  File \"C:\\Users\\tanzi\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 508, in _validate_hyperparameters\n    raise ValueError(\"learning rate %s is not supported. \" % self.learning_rate)\nValueError: learning rate 10 is not supported. \n\n--------------------------------------------------------------------------------\n45 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\tanzi\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\tanzi\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 762, in fit\n    return self._fit(X, y, incremental=False)\n  File \"C:\\Users\\tanzi\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 385, in _fit\n    self._validate_hyperparameters()\n  File \"C:\\Users\\tanzi\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 508, in _validate_hyperparameters\n    raise ValueError(\"learning rate %s is not supported. \" % self.learning_rate)\nValueError: learning rate 50 is not supported. \n\n--------------------------------------------------------------------------------\n45 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\Users\\tanzi\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\Users\\tanzi\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 762, in fit\n    return self._fit(X, y, incremental=False)\n  File \"C:\\Users\\tanzi\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 385, in _fit\n    self._validate_hyperparameters()\n  File \"C:\\Users\\tanzi\\CS Lang IDE\\PycharmProjects\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\", line 508, in _validate_hyperparameters\n    raise ValueError(\"learning rate %s is not supported. \" % self.learning_rate)\nValueError: learning rate 100 is not supported. \n"
     ]
    }
   ],
   "source": [
    "# fit the grid search\n",
    "# grid_search.fit(crime_df.drop(columns=['ViolentCrimesPerPop']), crime_df['ViolentCrimesPerPop'])\n",
    "grid_search.fit(X_train, y_train)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'cv_results_'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [148], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# time required to perform cross-validation\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m cv_time \u001B[38;5;241m=\u001B[39m \u001B[43mgrid_search\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcv_results_\u001B[49m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmean_fit_time\u001B[39m\u001B[38;5;124m'\u001B[39m][grid_search\u001B[38;5;241m.\u001B[39mbest_index_]\n\u001B[0;32m      4\u001B[0m \u001B[38;5;66;03m# mean and standard deviation of the performance metrics\u001B[39;00m\n\u001B[0;32m      5\u001B[0m ht_stats \u001B[38;5;241m=\u001B[39m collate_ht_results(grid_search, metric_keys, display\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'GridSearchCV' object has no attribute 'cv_results_'"
     ]
    }
   ],
   "source": [
    "\n",
    "# time required to perform cross-validation\n",
    "cv_time = grid_search.cv_results_['mean_fit_time'][grid_search.best_index_]\n",
    "\n",
    "# mean and standard deviation of the performance metrics\n",
    "ht_stats = collate_ht_results(grid_search, metric_keys, display=False)\n",
    "\n",
    "# weights of the best performing model\n",
    "coefficients = grid_search.best_estimator_.coefs_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.6 Final Models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Using the full training set (**training + validation**), train *two* linear regression models, one with and without PCA preprocessing, then apply them to the test set. For LASSO and MLP, you can utilize the best models found during cross-validation and just apply them to the test set.\n",
    "2. Create a bar chart of the three regression metrics for each model on the same plot.\n",
    "3. How do the models's performances compare? What do the metrics reveal about the dataset?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "outputs": [],
   "source": [
    "# Perform PCA\n",
    "pca_crime = PCA(n_components=8)\n",
    "pca_crime.fit(crime_df)\n",
    "\n",
    "# Split data into training and test sets\n",
    "train_crime, test_crime, train_labels, test_labels = train_test_split(crime_df, crime_df['ViolentCrimesPerPop'], test_size=0.2, random_state=23508893)\n",
    "train_crime_pca, test_crime_pca, train_labels_pca, test_labels_pca = train_test_split(pca_crime.transform(crime_df), crime_df['ViolentCrimesPerPop'], test_size=0.2, random_state=23508893)\n",
    "\n",
    "# Perform linear regression without PCA\n",
    "lr_crime = LinearRegression()\n",
    "lr_crime.fit(train_crime, train_labels)\n",
    "\n",
    "# Perform linear regression with PCA\n",
    "pca_lr_crime = LinearRegression()\n",
    "pca_lr_crime.fit(train_crime_pca, train_labels_pca)\n",
    "\n",
    "# Make predictions\n",
    "predictions_lr = lr_crime.predict(test_crime)\n",
    "predictions_pca_lr = pca_lr_crime.predict(test_crime_pca)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for linear regression without PCA:  5.052330785979026e-12\n",
      "RMSE for linear regression with PCA:  0.1503187928263025\n",
      "R2 for linear regression without PCA:  1.0\n",
      "R2 for linear regression with PCA:  0.5779774523434447\n",
      "MAE for linear regression without PCA:  3.883176261029911e-12\n",
      "MAE for linear regression with PCA:  0.11158023574151017\n"
     ]
    }
   ],
   "source": [
    "# Calculate the RMSE\n",
    "rmse=np.sqrt(mean_squared_error(test_labels, predictions_lr))\n",
    "print(\"RMSE for linear regression without PCA: \", rmse)\n",
    "rmse_pca=np.sqrt(mean_squared_error(test_labels_pca, predictions_pca_lr))\n",
    "print(\"RMSE for linear regression with PCA: \", rmse_pca)\n",
    "\n",
    "# Calculate R2\n",
    "r2=r2_score(test_labels, predictions_lr)\n",
    "print(\"R2 for linear regression without PCA: \",r2 )\n",
    "r2_pca=r2_score(test_labels_pca, predictions_pca_lr)\n",
    "print(\"R2 for linear regression with PCA: \",r2_pca )\n",
    "\n",
    "# Calculate MAE\n",
    "mae=mean_absolute_error(test_labels, predictions_lr)\n",
    "print(\"MAE for linear regression without PCA: \",mae )\n",
    "mae_pca=mean_absolute_error(test_labels_pca, predictions_pca_lr)\n",
    "print(\"MAE for linear regression with PCA: \",mae_pca)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1200x1000 with 4 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA+kAAANECAYAAADMv25PAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB4wUlEQVR4nOzdf1xUdd7//+cAwviLsSJBiCTTNBeDEiXsB9o1ReWadG2fUEuIj7mfWnMtyhRXpd+4lS7tarG6erltmqxtuV7qRRmX9mOlTJCrdVet7ReuOSBXOaOYYMx8//DbtBODMcSP9+DjfrudW857Xu8z73NuzbznyTlzjsXj8XgEAAAAAAC6XEhXDwAAAAAAAJxCSAcAAAAAwBCEdAAAAAAADEFIBwAAAADAEIR0AAAAAAAMQUgHAAAAAMAQhHQAAAAAAAxBSAcAAAAAwBCEdAAAAAAADEFIBwAAAADAEIR0IIitXr1aFovFu4SFhSkuLk533HGHDh486FM7duxYWSwWDRkyxO+6tm7d6l3PSy+95PPcX//6V91yyy0aOHCgrFar4uLidO211+o3v/mNT11CQoLPeP51uf7669t34wEAgF+t/X7gdru1evVq3XTTTYqPj1fv3r2VmJioxx57TCdOnOjCLQDObGFdPQAAP9wjjzyiCy64QCdOnNA777yj1atX6+2339aePXtktVq9dVarVf/4xz+0c+dOjR492mcda9askdVqbTYp79ixQ+PGjdP555+v6dOnKyYmRgcOHNA777yjZ555RjNnzvSpT05O1v33399sjLGxse24xQAA4Pt83/eD48ePKzc3V5dffrnuuusu9e/fX+Xl5SooKFBZWZn++7//WxaLpas3AzjjENKBbuCGG25QSkqKJOnOO+9UVFSUfvnLX2rjxo269dZbvXUXXnihvv76a7344os+If3EiRN65ZVXNH78eP3pT3/yWffjjz8um82m9957T/369fN5rra2ttlY4uLidPvtt7fj1gEAgLb4vu8H4eHh+stf/qIxY8Z4+0yfPl0JCQneoG6327tq+MAZi9PdgW7oqquukiR99NFHzZ6bPHmySkpK5Ha7vW3/+Z//qePHj/sE+m989NFH+tGPftQsoEtS//7922/QAACgQ333+0F4eLhPQP/GzTffLEnau3dv5w0OgBchHeiGPv30U0nSWWed1ey5KVOm6NChQ9q+fbu3be3atfq3f/s3v6F74MCBqqio0J49e1r12idPnlRdXV2z5auvvmrTtgAAgPZxuu8H/8rhcEiSoqKiOnpIAPwgpAPdgNPpVF1dnf75z3/qT3/6kx5++GFFREToxz/+cbPaIUOGKCUlRWvXrpUkHTlyRFu2bNGUKVP8rvuBBx7Q8ePHlZycrDFjxmjOnDl67bXXdPLkSb/1r732ms4999xmyzPPPNN+GwwAAL5XIN8P/tWTTz6pyMhI3XDDDZ00UgD/it+kA93Ad38vlpCQoBdeeEHnnXee3/opU6bo0Ucf1bPPPquXXnpJoaGhuvnmm1VRUdGs9tprr1V5ebkKCwv16quvqry8XE8++aTOPfdc/e53v9NNN93kU5+amqrHHnus2Xpauqo8AADoGIF+P5CkJ554Qq+//rqeffZZvz91A9DxCOlAN7Bs2TJddNFFcjqdWrVqld58801FRES0WD9p0iQ98MAD+q//+i+tWbNGP/7xj9W3b98W60eNGqWXX35ZjY2N+p//+R+98sor+tWvfqVbbrlFVVVVGj58uLc2KiqKi8wAAGCAQL8flJSUaP78+Zo2bZruvvvuThwpgH9FSAe6gdGjR3uv3pqZmakrr7xSU6ZM0f79+9WnT59m9QMGDNDYsWO1ePFi/eUvf2l2RfeWhIeHa9SoURo1apQuuugi5ebmav369SooKGjX7QEAAD9cIN8Ptm7dquzsbI0fP17FxcVdMVwA/z9+kw50M6GhoSosLNTnn3+upUuXtlg3ZcoUvfXWW4qMjNSNN94Y8Ot8M+kfOnSozWMFAACd43TfD959913dfPPNSklJ0R//+EeFhXEcD+hKhHSgGxo7dqxGjx6toqIinThxwm/NLbfcooKCAj377LMKDw9vcV3btm2Tx+Np1r5lyxZJ0tChQ9tn0AAAoEP5+36wd+9ejR8/XgkJCdq0aZN69uzZxaMEwJ/JgG5q9uzZ+j//5/9o9erVuuuuu5o9b7PZ9NBDD33vembOnKnjx4/r5ptv1rBhw9TY2KgdO3aopKRECQkJys3N9ak/ePCgXnjhhWbr6dOnjzIzM9u6OQAAoB386/eD2267TRkZGfryyy81e/Zsbd682af2wgsvVFpaWheNFDhzEdKBburf//3fdeGFF+rpp5/W9OnT27yep59+WuvXr9eWLVu0fPlyNTY26vzzz9fPfvYzzZ8/v9mVX6uqqjR16tRm6xk4cCAhHQCALvav3w+uvfZaHThwQJI0d+7cZrU5OTmEdKALWDz+zmMFAAAAAACdjt+kAwAAAABgCEI6AAAAAACGIKQDAAAAAGAIQjoAAAAAAIYgpAMAAAAAYAhCOgAAAAAAhugW90l3u936/PPP1bdvX1kslq4eDgAA8ng8Onr0qGJjYxUSwt/E2wPzPQDAJB0113eLkP75558rPj6+q4cBAEAzBw4c0HnnndfVw+gWmO8BACZq77m+W4T0vn37Sjq1cyIjI7t4NAAASC6XS/Hx8d45Cj8c8z0AwCQdNdd3i5D+zSlvkZGRTNoAAKNwWnb7Yb4HAJioved6fiQHAAAAAIAhCOkAAAAAABiCkA4AAAAAgCEI6QAAAAAAGIKQDgAAAACAIQjpAAAAAAAYgpAOAAAAAIAhCOkAAAAAABiCkA4AAAAAgCEI6QAAAAAAGIKQDgAAAvbmm29qwoQJio2NlcVi0YYNG763z/bt23XZZZcpIiJCgwcP1urVqzt8nAAABBtCOgAACFh9fb2SkpK0bNmyVtV/8sknGj9+vMaNG6eqqirde++9uvPOO/Xqq6928EgBAAguYV09AAAAEHxuuOEG3XDDDa2uLy4u1gUXXKDFixdLki6++GK9/fbb+tWvfqWMjIyOGiYAAEGHI+kAAKDDlZeXy263+7RlZGSovLy8xT4NDQ1yuVw+CwAA3R1H0gF0Doulq0cAtI7H09Uj6JYcDoeio6N92qKjo+VyufTVV1+pZ8+ezfoUFhbq4Ycf7rAx8bGEYMHHEnBm4Ug6AAAwUn5+vpxOp3c5cOBAVw8JAIAOx5F0AADQ4WJiYlRTU+PTVlNTo8jISL9H0SUpIiJCERERnTE8AACMwZF0AADQ4dLS0lRWVubTtnXrVqWlpXXRiAAAMBMhHQAABOzYsWOqqqpSVVWVpFO3WKuqqlJ1dbWkU6eqZ2dne+vvuusuffzxx3rwwQe1b98+Pfvss/rjH/+o++67ryuGDwCAsQjpAAAgYLt27dKll16qSy+9VJKUl5enSy+9VAsXLpQkHTp0yBvYJemCCy7Q5s2btXXrViUlJWnx4sX63e9+x+3XAAD4DovHE/zXi3S5XLLZbHI6nYqMjOzq4QDwh8soI1i007TI3NT+2nuf8rGEYBH839aB7qmj5nqOpAMAAAAAYAhCOgAAAAAAhiCkAwAAAABgCEI6AAAAAACGIKQDAAAAAGAIQjoAAAAAAIYgpAMAAAAAYAhCOgAAAAAAhiCkAwAAAABgCEI6AAAAAACGIKQDAAAAAGCINoX0ZcuWKSEhQVarVampqdq5c2eLtX/729/0k5/8RAkJCbJYLCoqKjrtuhctWiSLxaJ77723LUMDAAAAACBoBRzSS0pKlJeXp4KCAlVWViopKUkZGRmqra31W3/8+HENGjRIixYtUkxMzGnX/d577+m3v/2tLrnkkkCHBQAAAABA0As4pC9ZskTTp09Xbm6uhg8fruLiYvXq1UurVq3yWz9q1Cg99dRTmjRpkiIiIlpc77Fjx3TbbbdpxYoVOuusswIdFgAAAAAAQS+gkN7Y2KiKigrZ7fZvVxASIrvdrvLy8h80kBkzZmj8+PE+6wYAAAAA4EwSFkhxXV2dmpqaFB0d7dMeHR2tffv2tXkQ69atU2Vlpd57771W1Tc0NKihocH72OVytfm1AQAAAAAwRZdf3f3AgQOaNWuW1qxZI6vV2qo+hYWFstls3iU+Pr6DRwkAAAAAQMcLKKRHRUUpNDRUNTU1Pu01NTXfe1G4llRUVKi2tlaXXXaZwsLCFBYWpjfeeEO//vWvFRYWpqampmZ98vPz5XQ6vcuBAwfa9NoAAAAAAJgkoJAeHh6ukSNHqqyszNvmdrtVVlamtLS0Ng3g3/7t3/TXv/5VVVVV3iUlJUW33XabqqqqFBoa2qxPRESEIiMjfRYAAAAAAIJdQL9Jl6S8vDzl5OQoJSVFo0ePVlFRkerr65WbmytJys7OVlxcnAoLCyWdutjc3//+d++/Dx48qKqqKvXp00eDBw9W3759lZiY6PMavXv31jnnnNOsHQAAAACA7izgkJ6VlaXDhw9r4cKFcjgcSk5OVmlpqfdictXV1QoJ+fYA/eeff65LL73U+/jpp5/W008/rfT0dG3fvv2HbwEAAAAAAN2ExePxeLp6ED+Uy+WSzWaT0+nk1HfAVBZLV48AaJ12mhaZm9pfe+9TPpYQLIL/2zrQPXXUXN/lV3cHAAAAAACnENIBAAAAADAEIR0AAAAAAEMQ0gEAAAAAMAQhHQAAAAAAQxDSAQAAAAAwBCEdAAAAAABDENIBAAAAADAEIR0AAAAAAEMQ0gEAAAAAMAQhHQAAAAAAQxDSAQAAAAAwBCEdAAAAAABDENIBAAAAADAEIR0AAAAAAEMQ0gEAAAAAMAQhHQAAAAAAQxDSAQAAAAAwBCEdAAAAAABDENIBAAAAADAEIR0AAAAAAEMQ0gEAAAAAMAQhHQAAAAAAQxDSAQAAAAAwBCEdAAAAAABDENIBAAAAADAEIR0AAAAAAEMQ0gEAAAAAMAQhHQAAAAAAQxDSAQAAAAAwBCEdAAAAAABDENIBAAAAADAEIR0AAAAAAEMQ0gEAQJssW7ZMCQkJslqtSk1N1c6dO09bX1RUpKFDh6pnz56Kj4/XfffdpxMnTnTSaAEACA5tCumBTMp/+9vf9JOf/EQJCQmyWCwqKipqVlNYWKhRo0apb9++6t+/vzIzM7V///62DA0AAHSCkpIS5eXlqaCgQJWVlUpKSlJGRoZqa2v91q9du1Zz585VQUGB9u7dq5UrV6qkpETz5s3r5JEDAGC2gEN6oJPy8ePHNWjQIC1atEgxMTF+a9544w3NmDFD77zzjrZu3aqTJ0/quuuuU319faDDAwAAnWDJkiWaPn26cnNzNXz4cBUXF6tXr15atWqV3/odO3boiiuu0JQpU5SQkKDrrrtOkydP/t6j7wAAnGkCDumBTsqjRo3SU089pUmTJikiIsJvTWlpqe644w796Ec/UlJSklavXq3q6mpVVFQEOjwAANDBGhsbVVFRIbvd7m0LCQmR3W5XeXm53z5jxoxRRUWFN5R//PHH2rJli2688cZOGTMAAMEiLJDibybl/Px8b9v3Tcpt4XQ6JUlnn3223+cbGhrU0NDgfexyudrttQEAwOnV1dWpqalJ0dHRPu3R0dHat2+f3z5TpkxRXV2drrzySnk8Hn399de66667Tnu6O/M9AOBMFNCR9NNNyg6Ho10G5Ha7de+99+qKK65QYmKi35rCwkLZbDbvEh8f3y6vDQAAOsb27dv1xBNP6Nlnn1VlZaVefvllbd68WY8++miLfZjvAQBnIuOu7j5jxgzt2bNH69ata7EmPz9fTqfTuxw4cKATRwgAwJktKipKoaGhqqmp8Wmvqalp8fozCxYs0NSpU3XnnXdqxIgRuvnmm/XEE0+osLBQbrfbbx/mewDAmSigkN6WSTkQ99xzjzZt2qRt27bpvPPOa7EuIiJCkZGRPgsAAOgc4eHhGjlypMrKyrxtbrdbZWVlSktL89vn+PHjCgnx/doRGhoqSfJ4PH77MN8DAM5EAYX0tkzKreHxeHTPPffolVde0X//93/rggsuaPO6AABAx8vLy9OKFSv0+9//Xnv37tXdd9+t+vp65ebmSpKys7N9rmEzYcIEPffcc1q3bp0++eQTbd26VQsWLNCECRO8YR0AAAR44Tjp1KSck5OjlJQUjR49WkVFRc0m5bi4OBUWFko6dbG5v//9795/Hzx4UFVVVerTp48GDx4s6dQp7mvXrtWf//xn9e3b1/v7dpvNpp49e7bLhgIAgPaTlZWlw4cPa+HChXI4HEpOTlZpaan3ujXV1dU+R87nz58vi8Wi+fPn6+DBgzr33HM1YcIEPf744121CQAAGMniaekcs9NYunSpnnrqKe+k/Otf/1qpqamSpLFjxyohIUGrV6+WJH366ad+j4ynp6dr+/btpwZhsfh9nf/4j//QHXfc8b3jcblcstlscjqdnAoHmKqF9zlgnMCnRb+Ym9pfe+9TPpYQLNrpYwlAO+uoub5NId00fBECggDfhhEsCOnGIqTjTBX839aB7qmj5nrjru4OAAAAAMCZipAOAAAAAIAhCOkAAAAAABiCkA4AAAAAgCEI6QAAAAAAGIKQDgAAAACAIQjpAAAAAAAYgpAOAAAAAIAhCOkAAAAAABiCkA4AAAAAgCEI6QAAAAAAGIKQDgAAAACAIQjpAAAAAAAYgpAOAAAAAIAhCOkAAAAAABiCkA4AAAAAgCEI6QAAAAAAGIKQDgAAAACAIQjpAAAAAAAYgpAOAAAAAIAhCOkAAAAAABiCkA4AAAAAgCEI6QAAAAAAGIKQDgAAAACAIQjpAAAAAAAYgpAOAAAAAIAhCOkAAAAAABiCkA4AAAAAgCEI6QAAAAAAGIKQDgAAAACAIQjpAAAAAAAYgpAOAAAAAIAhCOkAAAAAABiiTSF92bJlSkhIkNVqVWpqqnbu3Nli7d/+9jf95Cc/UUJCgiwWi4qKin7wOgEAAAAA6I4CDuklJSXKy8tTQUGBKisrlZSUpIyMDNXW1vqtP378uAYNGqRFixYpJiamXdYJAAAAAEB3FHBIX7JkiaZPn67c3FwNHz5cxcXF6tWrl1atWuW3ftSoUXrqqac0adIkRUREtMs6AQAAAADojgIK6Y2NjaqoqJDdbv92BSEhstvtKi8vb9MAOmKdAAAAAAAEo7BAiuvq6tTU1KTo6Gif9ujoaO3bt69NA2jLOhsaGtTQ0OB97HK52vTaAAAAAACYJCiv7l5YWCibzeZd4uPju3pIAAAAAAD8YAGF9KioKIWGhqqmpsanvaampsWLwnXEOvPz8+V0Or3LgQMH2vTaAAAAAACYJKCQHh4erpEjR6qsrMzb5na7VVZWprS0tDYNoC3rjIiIUGRkpM8CAAAAAECwC+g36ZKUl5ennJwcpaSkaPTo0SoqKlJ9fb1yc3MlSdnZ2YqLi1NhYaGkUxeG+/vf/+7998GDB1VVVaU+ffpo8ODBrVonAAAAAABngoBDelZWlg4fPqyFCxfK4XAoOTlZpaWl3gu/VVdXKyTk2wP0n3/+uS699FLv46efflpPP/200tPTtX379latEwAAAACAM4HF4/F4unoQP5TL5ZLNZpPT6eTUd8BUFktXjwBonXaaFpmb2l9771M+lhAsgv/bOtA9ddRcH5RXdwcAAAAAoDsipAMAAAAAYAhCOgAAAAAAhiCkAwAAAABgCEI6AAAAAACGIKQDAAAAAGAIQjoAAAAAAIYgpAMAAAAAYAhCOgAAAAAAhiCkAwAAAABgCEI6AAAAAACGIKQDAIA2WbZsmRISEmS1WpWamqqdO3eetv7IkSOaMWOGBgwYoIiICF100UXasmVLJ40WAIDgENbVAwAAAMGnpKREeXl5Ki4uVmpqqoqKipSRkaH9+/erf//+zeobGxt17bXXqn///nrppZcUFxenzz77TP369ev8wQMAYDBCOgAACNiSJUs0ffp05ebmSpKKi4u1efNmrVq1SnPnzm1Wv2rVKn3xxRfasWOHevToIUlKSEjozCEDABAUON0dAAAEpLGxURUVFbLb7d62kJAQ2e12lZeX++2zceNGpaWlacaMGYqOjlZiYqKeeOIJNTU1tfg6DQ0NcrlcPgsAAN0dIR0AAASkrq5OTU1Nio6O9mmPjo6Ww+Hw2+fjjz/WSy+9pKamJm3ZskULFizQ4sWL9dhjj7X4OoWFhbLZbN4lPj6+XbcDAAATEdIBAECHc7vd6t+/v5YvX66RI0cqKytLv/jFL1RcXNxin/z8fDmdTu9y4MCBThwxAABdg9+kAwCAgERFRSk0NFQ1NTU+7TU1NYqJifHbZ8CAAerRo4dCQ0O9bRdffLEcDocaGxsVHh7erE9ERIQiIiLad/AAABiOI+kAACAg4eHhGjlypMrKyrxtbrdbZWVlSktL89vniiuu0D/+8Q+53W5v2wcffKABAwb4DegAAJypCOkAACBgeXl5WrFihX7/+99r7969uvvuu1VfX++92nt2drby8/O99Xfffbe++OILzZo1Sx988IE2b96sJ554QjNmzOiqTQAAwEic7g4AAAKWlZWlw4cPa+HChXI4HEpOTlZpaan3YnLV1dUKCfn2WEB8fLxeffVV3XfffbrkkksUFxenWbNmac6cOV21CQAAGMni8Xg8XT2IH8rlcslms8npdCoyMrKrhwPAH4ulq0cAtE47TYvMTe2vvfcpH0sIFsH/bR3onjpqrud0dwAAAAAADMHp7gAAAAB+OE5PQbAw/PQUjqQDAAAAAGAIQjoAAAAAAIYgpAMAAAAAYAhCOgAAAAAAhiCkAwAAAABgCEI6AAAAAACGIKQDAAAAAGAIQjoAAAAAAIYgpAMAAAAAYIg2hfRly5YpISFBVqtVqamp2rlz52nr169fr2HDhslqtWrEiBHasmWLz/PHjh3TPffco/POO089e/bU8OHDVVxc3JahAQAAAAAQtAIO6SUlJcrLy1NBQYEqKyuVlJSkjIwM1dbW+q3fsWOHJk+erGnTpmn37t3KzMxUZmam9uzZ463Jy8tTaWmpXnjhBe3du1f33nuv7rnnHm3cuLHtWwYAAAAAQJCxeDweTyAdUlNTNWrUKC1dulSS5Ha7FR8fr5kzZ2ru3LnN6rOyslRfX69NmzZ52y6//HIlJyd7j5YnJiYqKytLCxYs8NaMHDlSN9xwgx577LHvHZPL5ZLNZpPT6VRkZGQgmwOgs1gsXT0CoHUCmxZbxNzU/tp7n/KxhGDRTh9LHY83FYKF4XN9QEfSGxsbVVFRIbvd/u0KQkJkt9tVXl7ut095eblPvSRlZGT41I8ZM0YbN27UwYMH5fF4tG3bNn3wwQe67rrrAhkeAAAAAABBLSyQ4rq6OjU1NSk6OtqnPTo6Wvv27fPbx+Fw+K13OBzex7/5zW/005/+VOedd57CwsIUEhKiFStW6Oqrr/a7zoaGBjU0NHgfu1yuQDYDAAAAAAAjGXF199/85jd65513tHHjRlVUVGjx4sWaMWOGXn/9db/1hYWFstls3iU+Pr6TRwwAAAAAQPsL6Eh6VFSUQkNDVVNT49NeU1OjmJgYv31iYmJOW//VV19p3rx5euWVVzR+/HhJ0iWXXKKqqio9/fTTzU6Vl6T8/Hzl5eV5H7tcLoI6AAAAACDoBXQkPTw8XCNHjlRZWZm3ze12q6ysTGlpaX77pKWl+dRL0tatW731J0+e1MmTJxUS4juU0NBQud1uv+uMiIhQZGSkzwIAAAAAQLAL6Ei6dOp2aTk5OUpJSdHo0aNVVFSk+vp65ebmSpKys7MVFxenwsJCSdKsWbOUnp6uxYsXa/z48Vq3bp127dql5cuXS5IiIyOVnp6u2bNnq2fPnho4cKDeeOMNPf/881qyZEk7bioAAAAAAGYLOKRnZWXp8OHDWrhwoRwOh5KTk1VaWuq9OFx1dbXPUfExY8Zo7dq1mj9/vubNm6chQ4Zow4YNSkxM9NasW7dO+fn5uu222/TFF19o4MCBevzxx3XXXXe1wyYCAAAAABAcAr5Puom4Fy0QBLh3KoKF4fdOPZNxn3ScqYLm2zpvKgQLw+d6I67uDgAAAAAACOkAAAAAABiDkA4AAAAAgCEI6QAAAAAAGIKQDgAAAACAIQjpAAAAAAAYgpAOAAAAAIAhCOkAAAAAABiCkA4AAAAAgCEI6QAAAAAAGIKQDgAAAACAIQjpAAAAAAAYgpAOAAAAAIAhCOkAAAAAABiCkA4AAAAAgCEI6QAAAAAAGIKQDgAAAACAIQjpAAAAAAAYgpAOAAAAAIAhCOkAAAAAABiCkA4AAAAAgCEI6QAAAAAAGIKQDgAAAACAIQjpAAAAAAAYgpAOAAAAAIAhCOkAAAAAABiCkA4AAAAAgCEI6QAAAAAAGIKQDgAAAACAIQjpAAAAAAAYgpAOAAAAAIAhCOkAAAAAABiCkA4AAAAAgCEI6QAAoE2WLVumhIQEWa1WpaamaufOna3qt27dOlksFmVmZnbsAAEACEJtCumBTsrr16/XsGHDZLVaNWLECG3ZsqVZzd69e3XTTTfJZrOpd+/eGjVqlKqrq9syPAAA0MFKSkqUl5engoICVVZWKikpSRkZGaqtrT1tv08//VQPPPCArrrqqk4aKQAAwSXgkB7opLxjxw5NnjxZ06ZN0+7du5WZmanMzEzt2bPHW/PRRx/pyiuv1LBhw7R9+3a9//77WrBggaxWa9u3DAAAdJglS5Zo+vTpys3N1fDhw1VcXKxevXpp1apVLfZpamrSbbfdpocffliDBg3qxNECABA8LB6PxxNIh9TUVI0aNUpLly6VJLndbsXHx2vmzJmaO3dus/qsrCzV19dr06ZN3rbLL79cycnJKi4uliRNmjRJPXr00B/+8Ic2bYTL5ZLNZpPT6VRkZGSb1gGgg1ksXT0CoHUCmxZb1J3npsbGRvXq1UsvvfSSzynrOTk5OnLkiP785z/77VdQUKD3339fr7zyiu644w4dOXJEGzZsaPXrtvc+5WMJwaKdPpY6Hm8qBAvD5/qAjqQ3NjaqoqJCdrv92xWEhMhut6u8vNxvn/Lycp96ScrIyPDWu91ubd68WRdddJEyMjLUv39/paamnnbSbmhokMvl8lkAAEDnqKurU1NTk6Kjo33ao6Oj5XA4/PZ5++23tXLlSq1YsaLVr8N8DwA4EwUU0tsyKTscjtPW19bW6tixY1q0aJGuv/56vfbaa7r55pv17//+73rjjTf8rrOwsFA2m827xMfHB7IZAACgEx09elRTp07VihUrFBUV1ep+zPcAgDNRWFcPwO12S5ImTpyo++67T5KUnJysHTt2qLi4WOnp6c365OfnKy8vz/vY5XIxcQMA0EmioqIUGhqqmpoan/aamhrFxMQ0q//oo4/06aefasKECd62b+b/sLAw7d+/XxdeeGGzfsz3AIAzUUAhPdBJWZJiYmJOWx8VFaWwsDANHz7cp+biiy/W22+/7XedERERioiICGToAACgnYSHh2vkyJEqKyvz/ibd7XarrKxM99xzT7P6YcOG6a9//atP2/z583X06FE988wzLQZv5nsAwJkooNPd/3VS/sY3k3JaWprfPmlpaT71krR161ZvfXh4uEaNGqX9+/f71HzwwQcaOHBgIMMDAACdJC8vTytWrNDvf/977d27V3fffbfq6+uVm5srScrOzlZ+fr4kyWq1KjEx0Wfp16+f+vbtq8TERIWHh3flpgAAYJSAT3fPy8tTTk6OUlJSNHr0aBUVFTWblOPi4lRYWChJmjVrltLT07V48WKNHz9e69at065du7R8+XLvOmfPnq2srCxdffXVGjdunEpLS/Wf//mf2r59e/tsJQAAaFdZWVk6fPiwFi5cKIfDoeTkZJWWlnqvQ1NdXa2QkIDv9AoAwBkv4FuwSdLSpUv11FNPeSflX//610pNTZUkjR07VgkJCVq9erW3fv369Zo/f74+/fRTDRkyRE8++aRuvPFGn3WuWrVKhYWF+uc//6mhQ4fq4Ycf1sSJE1s1nu58mxug2+C2LAgWht+W5UzGLdhwpuIWbEA7M3yub1NINw1fhIAgwMSNYGH4xH0mI6TjTBU039Z5UyFYGD7Xcx4aAAAAAACGIKQDAAAAAGAIQjoAAAAAAIYgpAMAAAAAYAhCOgAAAAAAhiCkAwAAAABgCEI6AAAAAACGIKQDAAAAAGAIQjoAAAAAAIYgpAMAAAAAYAhCOgAAAAAAhiCkAwAAAABgCEI6AAAAAACGIKQDAAAAAGAIQjoAAAAAAIYgpAMAAAAAYAhCOgAAAAAAhiCkAwAAAABgCEI6AAAAAACGIKQDAAAAAGAIQjoAAAAAAIYgpAMAAAAAYAhCOgAAAAAAhiCkAwAAAABgCEI6AAAAAACGIKQDAAAAAGAIQjoAAAAAAIYgpAMAAAAAYAhCOgAAAAAAhiCkAwAAAABgCEI6AAAAAACGIKQDAAAAAGAIQjoAAAAAAIZoU0hftmyZEhISZLValZqaqp07d562fv369Ro2bJisVqtGjBihLVu2tFh71113yWKxqKioqC1DAwAAAAAgaAUc0ktKSpSXl6eCggJVVlYqKSlJGRkZqq2t9Vu/Y8cOTZ48WdOmTdPu3buVmZmpzMxM7dmzp1ntK6+8onfeeUexsbGBbwkAAAAAAEEu4JC+ZMkSTZ8+Xbm5uRo+fLiKi4vVq1cvrVq1ym/9M888o+uvv16zZ8/WxRdfrEcffVSXXXaZli5d6lN38OBBzZw5U2vWrFGPHj3atjUAAAAAAASxgEJ6Y2OjKioqZLfbv11BSIjsdrvKy8v99ikvL/epl6SMjAyferfbralTp2r27Nn60Y9+FMiQAAAAAADoNsICKa6rq1NTU5Oio6N92qOjo7Vv3z6/fRwOh996h8PhffzLX/5SYWFh+vnPf96qcTQ0NKihocH72OVytXYTAAAAAAAwVpdf3b2iokLPPPOMVq9eLYvF0qo+hYWFstls3iU+Pr6DRwkAAAAAQMcLKKRHRUUpNDRUNTU1Pu01NTWKiYnx2ycmJua09W+99ZZqa2t1/vnnKywsTGFhYfrss890//33KyEhwe868/Pz5XQ6vcuBAwcC2QwAAAAAAIwUUEgPDw/XyJEjVVZW5m1zu90qKytTWlqa3z5paWk+9ZK0detWb/3UqVP1/vvvq6qqyrvExsZq9uzZevXVV/2uMyIiQpGRkT4LAAAAAADBLqDfpEtSXl6ecnJylJKSotGjR6uoqEj19fXKzc2VJGVnZysuLk6FhYWSpFmzZik9PV2LFy/W+PHjtW7dOu3atUvLly+XJJ1zzjk655xzfF6jR48eiomJ0dChQ3/o9gEAAAAAEDQCDulZWVk6fPiwFi5cKIfDoeTkZJWWlnovDlddXa2QkG8P0I8ZM0Zr167V/PnzNW/ePA0ZMkQbNmxQYmJi+20FAAAAAADdgMXj8Xi6ehA/lMvlks1mk9Pp5NR3wFStvDAk0OXaaVpkbmp/7b1P+VhCsAiab+u8qRAsDJ/ru/zq7gAAAAAA4BRCOgAAAAAAhiCkAwAAAABgCEI6AAAAAACGIKQDAAAAAGAIQjoAAAAAAIYgpAMAAAAAYAhCOgAAAAAAhiCkAwAAAABgCEI6AAAAAACGIKQDAAAAAGAIQjoAAGiTZcuWKSEhQVarVampqdq5c2eLtStWrNBVV12ls846S2eddZbsdvtp6wEAOFMR0gEAQMBKSkqUl5engoICVVZWKikpSRkZGaqtrfVbv337dk2ePFnbtm1TeXm54uPjdd111+ngwYOdPHIAAMxm8Xg8nq4exA/lcrlks9nkdDoVGRnZ1cMB4I/F0tUjAFqnnabF7j43paamatSoUVq6dKkkye12Kz4+XjNnztTcuXO/t39TU5POOussLV26VNnZ2a16zfbep3wsIVgEzbd13lQIFobP9RxJBwAAAWlsbFRFRYXsdru3LSQkRHa7XeXl5a1ax/Hjx3Xy5EmdffbZHTVMAACCUlhXDwAAAASXuro6NTU1KTo62qc9Ojpa+/bta9U65syZo9jYWJ+g/10NDQ1qaGjwPna5XG0bMAAAQYQj6QAAoFMtWrRI69at0yuvvCKr1dpiXWFhoWw2m3eJj4/vxFECANA1COkAACAgUVFRCg0NVU1NjU97TU2NYmJiTtv36aef1qJFi/Taa6/pkksuOW1tfn6+nE6ndzlw4MAPHjsAAKYjpAMAgICEh4dr5MiRKisr87a53W6VlZUpLS2txX5PPvmkHn30UZWWliolJeV7XyciIkKRkZE+CwAA3R2/SQcAAAHLy8tTTk6OUlJSNHr0aBUVFam+vl65ubmSpOzsbMXFxamwsFCS9Mtf/lILFy7U2rVrlZCQIIfDIUnq06eP+vTp02XbAQCAaQjpAAAgYFlZWTp8+LAWLlwoh8Oh5ORklZaWei8mV11drZCQb0/Ye+6559TY2KhbbrnFZz0FBQV66KGHOnPoAAAYjfukA+gc3DsVwcLwe6eeybhPOs5UQfNtnTcVgoXhcz2/SQcAAAAAwBCEdAAAAAAADEFIBwAAAADAEIR0AAAAAAAMQUgHAAAAAMAQhHQAAAAAAAxBSAcAAAAAwBCEdAAAAAAADEFIBwAAAADAEIR0AAAAAAAMQUgHAAAAAMAQbQrpy5YtU0JCgqxWq1JTU7Vz587T1q9fv17Dhg2T1WrViBEjtGXLFu9zJ0+e1Jw5czRixAj17t1bsbGxys7O1ueff96WoQEAAAAAELQCDuklJSXKy8tTQUGBKisrlZSUpIyMDNXW1vqt37FjhyZPnqxp06Zp9+7dyszMVGZmpvbs2SNJOn78uCorK7VgwQJVVlbq5Zdf1v79+3XTTTf9sC0DAAAAACDIWDwejyeQDqmpqRo1apSWLl0qSXK73YqPj9fMmTM1d+7cZvVZWVmqr6/Xpk2bvG2XX365kpOTVVxc7Pc13nvvPY0ePVqfffaZzj///O8dk8vlks1mk9PpVGRkZCCbA6CzWCxdPQKgdQKbFlvE3NT+2nuf8rGEYNFOH0sdjzcVgoXhc31AR9IbGxtVUVEhu93+7QpCQmS321VeXu63T3l5uU+9JGVkZLRYL0lOp1MWi0X9+vULZHgAAAAAAAS1sECK6+rq1NTUpOjoaJ/26Oho7du3z28fh8Pht97hcPitP3HihObMmaPJkye3+NeIhoYGNTQ0eB+7XK5ANgMAAAAAACMZdXX3kydP6tZbb5XH49Fzzz3XYl1hYaFsNpt3iY+P78RRAgAAAADQMQIK6VFRUQoNDVVNTY1Pe01NjWJiYvz2iYmJaVX9NwH9s88+09atW097Tn9+fr6cTqd3OXDgQCCbAQAAAACAkQIK6eHh4Ro5cqTKysq8bW63W2VlZUpLS/PbJy0tzadekrZu3epT/01A//DDD/X666/rnHPOOe04IiIiFBkZ6bMAAAAAABDsAvpNuiTl5eUpJydHKSkpGj16tIqKilRfX6/c3FxJUnZ2tuLi4lRYWChJmjVrltLT07V48WKNHz9e69at065du7R8+XJJpwL6LbfcosrKSm3atElNTU3e36ufffbZCg8Pb69tBQAAAADAaAGH9KysLB0+fFgLFy6Uw+FQcnKySktLvReHq66uVkjItwfox4wZo7Vr12r+/PmaN2+ehgwZog0bNigxMVGSdPDgQW3cuFGSlJyc7PNa27Zt09ixY9u4aQAAAAAABJeA75NuIu5FCwQB7p2KYGH4vVPPZNwnHWeqoPm2zpsKwcLwud6oq7sDAAAAAHAmI6QDAAAAAGAIQjoAAAAAAIYgpAMAAAAAYAhCOgAAAAAAhiCkAwAAAABgCEI6AAAAAACGIKQDAAAAAGAIQjoAAAAAAIYgpAMAAAAAYAhCOgAAAAAAhiCkAwAAAABgCEI6AAAAAACGIKQDAAAAAGAIQjoAAAAAAIYgpAMAAAAAYAhCOgAAAAAAhiCkAwAAAABgCEI6AAAAAACGIKQDAAAAAGAIQjoAAAAAAIYgpAMAAAAAYAhCOgAAAAAAhiCkAwAAAABgCEI6AAAAAACGIKQDAAAAAGAIQjoAAAAAAIYgpAMAAAAAYAhCOgAAAAAAhiCkAwAAAABgCEI6AAAAAACGIKQDAAAAAGAIQjoAAAAAAIYgpAMAAAAAYIg2hfRly5YpISFBVqtVqamp2rlz52nr169fr2HDhslqtWrEiBHasmWLz/Mej0cLFy7UgAED1LNnT9ntdn344YdtGRoAAOgk7f19AAAAtCGkl5SUKC8vTwUFBaqsrFRSUpIyMjJUW1vrt37Hjh2aPHmypk2bpt27dyszM1OZmZnas2ePt+bJJ5/Ur3/9axUXF+vdd99V7969lZGRoRMnTrR9ywAAQIfpiO8DAABAsng8Hk8gHVJTUzVq1CgtXbpUkuR2uxUfH6+ZM2dq7ty5zeqzsrJUX1+vTZs2edsuv/xyJScnq7i4WB6PR7Gxsbr//vv1wAMPSJKcTqeio6O1evVqTZo06XvH5HK5ZLPZ5HQ6FRkZGcjmAOgsFktXjwBoncCmxRZ197mpvb8PtEZ771M+lhAs2uljqePxpkKwMHyuDwukuLGxURUVFcrPz/e2hYSEyG63q7y83G+f8vJy5eXl+bRlZGRow4YNkqRPPvlEDodDdrvd+7zNZlNqaqrKy8v9hvSGhgY1NDR4HzudTkmndhIAAD9IO80l38xJAf4tPCh0xPcBf5jvgVP4Xx5oZ4bP9QGF9Lq6OjU1NSk6OtqnPTo6Wvv27fPbx+Fw+K13OBze579pa6nmuwoLC/Xwww83a4+Pj2/dhgAA0BKbrV1Xd/ToUdnaeZ1drSO+D/jDfA+c0s0+QoCuZ/hcH1BIN0V+fr7PX+Pdbre++OILnXPOObJwmo2RXC6X4uPjdeDAgW552ifQFXhfmc3j8ejo0aOKjY3t6qEELeb74MJnEtD+eF+ZraPm+oBCelRUlEJDQ1VTU+PTXlNTo5iYGL99YmJiTlv/zX9ramo0YMAAn5rk5GS/64yIiFBERIRPW79+/QLZFHSRyMhIPmCAdsb7ylzd7Qj6Nzri+4A/zPfBic8koP3xvjJXR8z1AV3dPTw8XCNHjlRZWZm3ze12q6ysTGlpaX77pKWl+dRL0tatW731F1xwgWJiYnxqXC6X3n333RbXCQAAuk5HfB8AAACnBHy6e15ennJycpSSkqLRo0erqKhI9fX1ys3NlSRlZ2crLi5OhYWFkqRZs2YpPT1dixcv1vjx47Vu3Trt2rVLy5cvlyRZLBbde++9euyxxzRkyBBdcMEFWrBggWJjY5WZmdl+WwoAANpNe38fAAAApwQc0rOysnT48GEtXLhQDodDycnJKi0t9V4Mprq6WiEh3x6gHzNmjNauXav58+dr3rx5GjJkiDZs2KDExERvzYMPPqj6+nr99Kc/1ZEjR3TllVeqtLRUVqu1HTYRJoiIiFBBQUGz0xYBtB3vK3Sljvg+gODGZxLQ/nhfnZkCvk86AAAAAADoGAH9Jh0AAAAAAHQcQjoAAAAAAIYgpAMAAAAAYAhC+hlq+/btslgsOnLkyGnrEhISVFRU1CljAs4kvAcBdDQ+Z4CuxXsQbUVID3LFxcXq27evvv76a2/bsWPH1KNHD40dO9an9psPio8++khjxozRoUOHZLPZJEmrV69Wv379OnHkvlr74ZSQkCCLxSKLxaLevXvrsssu0/r1631qXC6XfvGLX2jYsGGyWq2KiYmR3W7Xyy+/rO9eJ/HFF19UaGioZsyY0Z6bgzOIie/BO+64w/s+CQ8P1+DBg/XII4/4jNHj8Wj58uVKTU1Vnz591K9fP6WkpKioqEjHjx/3Wd8///lPhYeHcxVuoIuY+DnTFsz1CFYmvgeZ67s3QnqQGzdunI4dO6Zdu3Z529566y3FxMTo3Xff1YkTJ7zt27Zt0/nnn68LL7xQ4eHhiomJkcVi6Yph/yCPPPKIDh06pN27d2vUqFHKysrSjh07JElHjhzRmDFj9Pzzzys/P1+VlZV68803lZWVpQcffFBOp9NnXStXrtSDDz6oF1980WdfAa1l6nvw+uuv16FDh/Thhx/q/vvv10MPPaSnnnrK+/zUqVN17733auLEidq2bZuqqqq0YMEC/fnPf9Zrr73ms67Vq1fr1ltvlcvl0rvvvtsh4wXQMlM/ZzoScz1MYup7kLm+G/Mg6A0YMMBTWFjoffzggw96ZsyY4bn44os927Zt87ZfffXVnpycHI/H4/Fs27bNI8nz5Zdfev/9r0tBQYHH4/F4Bg4c6Hn88cc9ubm5nj59+nji4+M9v/3tb31e//333/eMGzfOY7VaPWeffbZn+vTpnqNHj3qfT09P98yaNcunz8SJE71jSU9Pb/b6LRk4cKDnV7/6lffxyZMnPb169fLMnTvX4/F4PHfffbend+/enoMHDzbre/ToUc/Jkye9jz/++GNPz549PUeOHPGkpqZ61qxZ0+LrAqfT1e/B78rJyfFMnDjRp+3aa6/1XH755R6Px+MpKSnxSPJs2LChWV+32+05cuSIz+NBgwZ5SktLPXPmzPFMnz49gD0DoL109ecMcz3OdF39Hvwu5vrujSPp3cC4ceO0bds27+Nt27Zp7NixSk9P97Z/9dVXevfddzVu3Lhm/ceMGaOioiJFRkbq0KFDOnTokB544AHv84sXL1ZKSop2796tn/3sZ7r77ru1f/9+SVJ9fb0yMjJ01lln6b333tP69ev1+uuv65577mn1+F9++WWdd9553r+aHzp0qNV9w8LC1KNHDzU2NsrtdmvdunW67bbbFBsb26y2T58+CgsL8z7+j//4D40fP142m0233367Vq5c2erXBf5VV74HW6tnz55qbGyUJK1Zs0ZDhw7VxIkTm9VZLBbvaXnfbMvx48dlt9t1++23a926daqvrw/otQH8cMz1zPXoWsz16EyE9G5g3Lhx+stf/qKvv/5aR48e1e7du5Wenq6rr75a27dvlySVl5eroaHB74dGeHi4bDabLBaLYmJiFBMToz59+nifv/HGG/Wzn/1MgwcP1pw5cxQVFeX9MFq7dq1OnDih559/XomJibrmmmu0dOlS/eEPf1BNTU2rxn/22WcrNDRUffv29b5+azQ2NqqwsFBOp1PXXHON6urq9OWXX2rYsGHf29ftdmv16tW6/fbbJUmTJk3S22+/rU8++aRVrw38q658D34fj8ej119/Xa+++qquueYaSdKHH36ooUOHtqr/ypUrNWnSJIWGhioxMVGDBg1q9ttQAB2PuZ65Hl2LuR6diZDeDYwdO1b19fV677339NZbb+miiy7Sueeeq/T0dO/vZLZv365Bgwbp/PPPD3j9l1xyifff33yw1NbWSpL27t2rpKQk9e7d21tzxRVXyO12B/zXv9aaM2eO+vTpo169eumXv/ylFi1apPHjxze7UMzpbN26VfX19brxxhslSVFRUbr22mu1atWqDhkzureufA+2ZNOmTerTp4+sVqtuuOEGZWVl6aGHHpKkVr9Xjhw5opdfftn7BVcSR6KALsJcz1yPrsVcj84U9v0lMN3gwYN13nnnadu2bfryyy+Vnp4uSYqNjVV8fLx27Nihbdu2ef+yFqgePXr4PLZYLHK73a3uHxIS0uyD4uTJk20aiyTNnj1bd9xxh/r06aPo6GjvxTjOPfdc9evXT/v27fvedaxcuVJffPGFevbs6W1zu916//339fDDDyskhL9fofVMfA+OGzdOzz33nMLDwxUbG+tz+udFF13UqvfJN0fPUlNTvW0ej0dut1sffPCBLrroogC3BEBbmfg586+Y69HdmfgeZK7vvvh06ibGjRun7du3a/v27T63grj66qv1X//1X9q5c6ffU2++ER4erqampoBf9+KLL9b//M//+Pxu5S9/+YtCQkK8p9ice+65Pr89a2pq0p49e9r8+lFRURo8eHCzq2WGhIRo0qRJWrNmjT7//PNm/Y4dO6avv/5a//u//6s///nPWrdunaqqqrzL7t279eWXXza72iXQGl31HmxJ7969NXjwYJ1//vk+k7YkTZkyRR988IH+/Oc/N+vn8Xi8V0ZeuXKl7r//fp/3yf/8z//oqquu4kgU0AWY65nr0bWY69FZCOndxLhx4/T222+rqqrK+5c9SUpPT9dvf/tbNTY2nvZDIyEhQceOHVNZWZnq6uqa3TuxJbfddpusVqtycnK0Z88ebdu2TTNnztTUqVMVHR0tSbrmmmu0efNmbd68Wfv27dPdd9+tI0eONHv9N998UwcPHlRdXV3gO+D/9/jjjys+Pl6pqal6/vnn9fe//10ffvihVq1apUsvvVTHjh3TH/7wB51zzjm69dZblZiY6F2SkpJ04403cnoP2qSr3oNtceuttyorK0uTJ0/WE088oV27dumzzz7Tpk2bZLfbvbdpqays1J133unzPklMTNTkyZP1+9//3uderAA6HnP9Kcz16CrM9egshPRuYty4cfrqq680ePBg74QpnfrQOHr0qIYOHaoBAwa02H/MmDG66667lJWVpXPPPVdPPvlkq163V69eevXVV/XFF19o1KhRuuWWW/Rv//ZvWrp0qbfm//7f/6ucnBxlZ2crPT1dgwYNavYB9sgjj+jTTz/VhRdeqHPPPTfArf/W2WefrXfeeUe33367HnvsMV166aW66qqr9OKLL+qpp56SzWbTqlWrdPPNN/u9Z+VPfvITbdy48Qd9ecCZqaveg21hsVi0du1aLVmyRBs2bFB6erouueQSPfTQQ5o4caIyMjK0cuVKDR8+3O/FmW6++WbV1tZqy5YtHTZGAM0x15/CXI+uwlyPzmLxBHIFDgAAAAAA0GE4kg4AAAAAgCEI6QAAAAAAGIKQDgAAAACAIQjpAAAAAAAYgpAOAAAAAIAhCOkAAAAAABiCkA4AAAAAgCEI6QAAAAAAGIKQDgAAAACAIQjpAAAAAAAYgpAOAAAAAIAhCOkAAAAAABiCkA4AAAAAgCEI6QAAAAAAGIKQDgAAAACAIQjpAAAAAAAYgpAOAAAAAIAhCOkAAAAAABiCkA4AAAAAgCEI6QAAAAAAGIKQDgAAAACAIQjpAAAAAAAYgpAOAAAAAIAhCOkAAAAAABiCkA4AAAAAgCEI6QAAAAAAGIKQDgAAAACAIQjpQDezevVqWSwWWSwWvf32282e93g8io+Pl8Vi0Y9//ONmzx85ckRWq1UWi0V79+71+xp33HGH9zW+u1it1nbfJgAAAOBMEdbVAwDQMaxWq9auXasrr7zSp/2NN97QP//5T0VERPjtt379elksFsXExGjNmjV67LHH/NZFRETod7/7XbP20NDQHz54AAAA4AxFSAe6qRtvvFHr16/Xr3/9a4WFfftWX7t2rUaOHKm6ujq//V544QXdeOONGjhwoNauXdtiSA8LC9Ptt9/eIWMHAAAAzlSc7g50U5MnT9b//u//auvWrd62xsZGvfTSS5oyZYrfPtXV1Xrrrbc0adIkTZo0SZ988ol27NjRWUMGAAAAzniEdKCbSkhIUFpaml588UVv23/913/J6XRq0qRJfvu8+OKL6t27t3784x9r9OjRuvDCC7VmzZoWX6Ourq7Z4nK52n1bAAAAgDMFIR3oxqZMmaINGzboq6++kiStWbNG6enpio2N9Vu/Zs0aTZw4UT179pQkZWVl6Y9//KO+/vrrZrX19fU699xzmy233nprx20QAAAA0M0R0oFu7NZbb9VXX32lTZs26ejRo9q0aVOLp7q///77+utf/6rJkyd72yZPnqy6ujq9+uqrzeqtVqu2bt3abFm0aFGHbQ8AAADQ3XHhOKAbO/fcc2W327V27VodP35cTU1NuuWWW/zWvvDCC+rdu7cGDRqkf/zjH5JOBfGEhAStWbNG48eP96kPDQ2V3W7v8G0AAAAAziSEdKCbmzJliqZPny6Hw6EbbrhB/fr1a1bj8Xj04osvqr6+XsOHD2/2fG1trY4dO6Y+ffp0wogBAACAMxchHejmbr75Zv2///f/9M4776ikpMRvzTf3Tn/kkUd08cUX+zz35Zdf6qc//ak2bNjALdcAAACADkZIB7q5Pn366LnnntOnn36qCRMm+K355lT32bNny2q1Nnv+qaee0po1awjpAAAAQAcjpANngJycnBafa2ho0J/+9Cdde+21fgO6JN1000165plnVFtbq/79+0uSvv76a73wwgt+62+++Wb17t37hw8cAAAAOMMQ0oEz3ObNm3XkyJEWj7JL0oQJE7R48WKtW7dOP//5zyWdCvdTp071W//JJ58Q0gEAAIA2sHg8Hk9XDwIAAAAAAHCfdAAAAAAAjEFIBwAAAADAEIR0AAAAAAAMQUgHAAABe/PNNzVhwgTFxsbKYrFow4YN39tn+/btuuyyyxQREaHBgwdr9erVHT5OAACCDSEdAAAErL6+XklJSVq2bFmr6j/55BONHz9e48aNU1VVle69917deeedevXVVzt4pAAABBeu7g4AAH4Qi8WiV155RZmZmS3WzJkzR5s3b9aePXu8bZMmTdKRI0dUWlraCaMEACA4dIv7pLvdbn3++efq27evLBZLVw8HAAB5PB4dPXpUsbGxCgnhxLXy8nLZ7XaftoyMDN17770t9mloaFBDQ4P3sdvt1hdffKFzzjmH+R4A0OU6aq7vFiH9888/V3x8fFcPAwCAZg4cOKDzzjuvq4fR5RwOh6Kjo33aoqOj5XK59NVXX6lnz57N+hQWFurhhx/urCECANAm7T3Xd4uQ3rdvX0mndk5kZGQXjwYAAMnlcik+Pt47RyFw+fn5ysvL8z52Op06//zzme8BAEboqLm+W4T0b055i4yMZNIGABiF07JPiYmJUU1NjU9bTU2NIiMj/R5Fl6SIiAhFREQ0a2e+BwCYpL3nen4kBwAAOlxaWprKysp82rZu3aq0tLQuGhEAAGYipAMAgIAdO3ZMVVVVqqqqknTqFmtVVVWqrq6WdOpU9ezsbG/9XXfdpY8//lgPPvig9u3bp2effVZ//OMfdd9993XF8AEAMBYhHQAABGzXrl269NJLdemll0qS8vLydOmll2rhwoWSpEOHDnkDuyRdcMEF2rx5s7Zu3aqkpCQtXrxYv/vd75SRkdEl4wcAwFTd4j7pLpdLNptNTqeT36gBAIzA3NT+2KcAAJN01LzEkXQAAAAAAAxBSAcAAAAAwBCEdAAAAAAADEFIBwAAAADAEIR0AAAAAAAMQUgHAAAAAMAQhHQAAAAAAAxBSAcAAAAAwBCEdAAAAAAADEFIBwAAAADAEGFdPQAAZwiLpatHALSOx9PVIwAAAGcwjqQDAAAAAGAIQjoAAAAAAIYgpAMAAAAAYAhCOgAAAAAAhiCkAwAAAABgCEI6AAAAAACGIKQDAAAAAGAIQjoAAAAAAIYgpAMAAAAAYAhCOgAAAAAAhiCkAwAAAABgCEI6AAAAAACGIKQDAAAAAGAIQjoAAAAAAIYgpAMAAAAAYAhCOgAAAAAAhiCkAwAAAABgCEI6AAAAAACGIKQDAAAAAGAIQjoAAAAAAIYgpAMAAAAAYAhCOgAAAAAAhiCkAwAAAABgCEI6AAAAAACGIKQDAAAAAGAIQjoAAAAAAIYgpAMAAAAAYAhCOgAAAAAAhiCkAwAAAABgiDaF9GXLlikhIUFWq1WpqanauXNni7V/+9vf9JOf/EQJCQmyWCwqKir6wesEAAAAAKA7Cjikl5SUKC8vTwUFBaqsrFRSUpIyMjJUW1vrt/748eMaNGiQFi1apJiYmHZZJwAAAAAA3VHAIX3JkiWaPn26cnNzNXz4cBUXF6tXr15atWqV3/pRo0bpqaee0qRJkxQREdEu6wQAAAAAoDsKKKQ3NjaqoqJCdrv92xWEhMhut6u8vLxNA+iIdQIAAAAAEIzCAimuq6tTU1OToqOjfdqjo6O1b9++Ng2gLetsaGhQQ0OD97HL5WrTawMAAAAAYJKgvLp7YWGhbDabd4mPj+/qIQEAAAAA8IMFFNKjoqIUGhqqmpoan/aampoWLwrXEevMz8+X0+n0LgcOHGjTawMAAAAAYJKAQnp4eLhGjhypsrIyb5vb7VZZWZnS0tLaNIC2rDMiIkKRkZE+CwAAAAAAwS6g36RLUl5ennJycpSSkqLRo0erqKhI9fX1ys3NlSRlZ2crLi5OhYWFkk5dGO7vf/+7998HDx5UVVWV+vTpo8GDB7dqnQAAAAAAnAkCDulZWVk6fPiwFi5cKIfDoeTkZJWWlnov/FZdXa2QkG8P0H/++ee69NJLvY+ffvppPf3000pPT9f27dtbtU4AAAAAAM4EFo/H4+nqQfxQLpdLNptNTqeTU98BU1ksXT0CoHXaaVpkbmp/7FMAgEk6al4Kyqu7AwAAAADQHRHSAQAAAAAwBCEdAAAAAABDENIBAAAAADAEIR0AAAAAAEMQ0gEAAAAAMAQhHQAAAAAAQxDSAQAAAAAwBCEdAAC0ybJly5SQkCCr1arU1FTt3LnztPVFRUUaOnSoevbsqfj4eN133306ceJEJ40WAIDgQEgHAAABKykpUV5engoKClRZWamkpCRlZGSotrbWb/3atWs1d+5cFRQUaO/evVq5cqVKSko0b968Th45AABmI6QDAICALVmyRNOnT1dubq6GDx+u4uJi9erVS6tWrfJbv2PHDl1xxRWaMmWKEhISdN1112ny5Mnfe/QdAIAzDSEdAAAEpLGxURUVFbLb7d62kJAQ2e12lZeX++0zZswYVVRUeEP5xx9/rC1btujGG29s8XUaGhrkcrl8FgAAuruwrh4AAAAILnV1dWpqalJ0dLRPe3R0tPbt2+e3z5QpU1RXV6crr7xSHo9HX3/9te66667Tnu5eWFiohx9+uF3HDgCA6TiSDgAAOtz27dv1xBNP6Nlnn1VlZaVefvllbd68WY8++miLffLz8+V0Or3LgQMHOnHEAAB0DY6kAwCAgERFRSk0NFQ1NTU+7TU1NYqJifHbZ8GCBZo6daruvPNOSdKIESNUX1+vn/70p/rFL36hkJDmxw0iIiIUERHR/hsAAIDBOJIOAAACEh4erpEjR6qsrMzb5na7VVZWprS0NL99jh8/3iyIh4aGSpI8Hk/HDRYAgCDDkXQAABCwvLw85eTkKCUlRaNHj1ZRUZHq6+uVm5srScrOzlZcXJwKCwslSRMmTNCSJUt06aWXKjU1Vf/4xz+0YMECTZgwwRvWAQAAIR0AALRBVlaWDh8+rIULF8rhcCg5OVmlpaXei8lVV1f7HDmfP3++LBaL5s+fr4MHD+rcc8/VhAkT9Pjjj3fVJgAAYCSLpxucY+ZyuWSz2eR0OhUZGdnVwwHgj8XS1SMAWqedpkXmpvbHPgUAmKSj5iV+kw4AAAAAgCEI6QAAAAAAGIKQDgAAAACAIQjpAAAAAAAYgpAOAAAAAIAhCOkAAAAAABiCkA4AAAAAgCEI6QAAAAAAGIKQDgAAAACAIQjpAAAAAAAYgpAOAAAAAIAhCOkAAAAAABiCkA4AAAAAgCEI6QAAAAAAGIKQDgAAAACAIQjpAAAAAAAYgpAOAAAAAIAhCOkAAAAAABiCkA4AAAAAgCEI6QAAAAAAGIKQDgAAAACAIQjpAAAAAAAYgpAOAAAAAIAhCOkAAAAAABiCkA4AAAAAgCEI6QAAAAAAGIKQDgAAAACAIQjpAAAAAAAYgpAOAAAAAIAhCOkAAAAAABiiTSF92bJlSkhIkNVqVWpqqnbu3Hna+vXr12vYsGGyWq0aMWKEtmzZ4vP8sWPHdM899+i8885Tz549NXz4cBUXF7dlaAAAAAAABK2AQ3pJSYny8vJUUFCgyspKJSUlKSMjQ7W1tX7rd+zYocmTJ2vatGnavXu3MjMzlZmZqT179nhr8vLyVFpaqhdeeEF79+7Vvffeq3vuuUcbN25s+5YBAAAAABBkLB6PxxNIh9TUVI0aNUpLly6VJLndbsXHx2vmzJmaO3dus/qsrCzV19dr06ZN3rbLL79cycnJ3qPliYmJysrK0oIFC7w1I0eO1A033KDHHnvse8fkcrlks9nkdDoVGRkZyOYA6CwWS1ePAGidwKbFFjE3tT/2KQDAJB01LwV0JL2xsVEVFRWy2+3friAkRHa7XeXl5X77lJeX+9RLUkZGhk/9mDFjtHHjRh08eFAej0fbtm3TBx98oOuuu87vOhsaGuRyuXwWAAAAAACCXUAhva6uTk1NTYqOjvZpj46OlsPh8NvH4XB8b/1vfvMbDR8+XOedd57Cw8N1/fXXa9myZbr66qv9rrOwsFA2m827xMfHB7IZAAAAAAAYyYiru//mN7/RO++8o40bN6qiokKLFy/WjBkz9Prrr/utz8/Pl9Pp9C4HDhzo5BEDAAAAAND+wgIpjoqKUmhoqGpqanzaa2pqFBMT47dPTEzMaeu/+uorzZs3T6+88orGjx8vSbrkkktUVVWlp59+utmp8pIUERGhiIiIQIYOAAAAAIDxAjqSHh4erpEjR6qsrMzb5na7VVZWprS0NL990tLSfOolaevWrd76kydP6uTJkwoJ8R1KaGio3G53IMMDAAAAACCoBXQkXTp1u7ScnBylpKRo9OjRKioqUn19vXJzcyVJ2dnZiouLU2FhoSRp1qxZSk9P1+LFizV+/HitW7dOu3bt0vLlyyVJkZGRSk9P1+zZs9WzZ08NHDhQb7zxhp5//nktWbKkHTcVAAAAAACzBRzSs7KydPjwYS1cuFAOh0PJyckqLS31Xhyuurra56j4mDFjtHbtWs2fP1/z5s3TkCFDtGHDBiUmJnpr1q1bp/z8fN1222364osvNHDgQD3++OO666672mETAQAAAAAIDgHfJ91E3DcVCALcJx3BgvukG4t9CgAwiRH3SQcAAAAAAB2HkA4AAAAAgCEI6QAAAAAAGIKQDgAAAACAIQjpAAAAAAAYgpAOAAAAAIAhCOkAAAAAABiCkA4AAAAAgCEI6QAAAAAAGIKQDgAAAACAIQjpAAAAAAAYgpAOAAAAAIAhCOkAAAAAABiCkA4AAAAAgCEI6QAAAAAAGIKQDgAAAACAIQjpAAAAAAAYgpAOAAAAAIAhCOkAAKBNli1bpoSEBFmtVqWmpmrnzp2nrT9y5IhmzJihAQMGKCIiQhdddJG2bNnSSaMFACA4hHX1AAAAQPApKSlRXl6eiouLlZqaqqKiImVkZGj//v3q379/s/rGxkZde+216t+/v1566SXFxcXps88+U79+/Tp/8AAAGIyQDgAAArZkyRJNnz5dubm5kqTi4mJt3rxZq1at0ty5c5vVr1q1Sl988YV27NihHj16SJISEhI6c8gAAAQFTncHAAABaWxsVEVFhex2u7ctJCREdrtd5eXlfvts3LhRaWlpmjFjhqKjo5WYmKgnnnhCTU1NLb5OQ0ODXC6XzwIAQHdHSAcAAAGpq6tTU1OToqOjfdqjo6PlcDj89vn444/10ksvqampSVu2bNGCBQu0ePFiPfbYYy2+TmFhoWw2m3eJj49v1+0AAMBEhHQAANDh3G63+vfvr+XLl2vkyJHKysrSL37xCxUXF7fYJz8/X06n07scOHCgE0cMAEDX4DfpAAAgIFFRUQoNDVVNTY1Pe01NjWJiYvz2GTBggHr06KHQ0FBv28UXXyyHw6HGxkaFh4c36xMREaGIiIj2HTwAAIbjSDoAAAhIeHi4Ro4cqbKyMm+b2+1WWVmZ0tLS/Pa54oor9I9//ENut9vb9sEHH2jAgAF+AzoAAGcqQjoAAAhYXl6eVqxYod///vfau3ev7r77btXX13uv9p6dna38/Hxv/d13360vvvhCs2bN0gcffKDNmzfriSee0IwZM7pqEwAAMBKnuwMAgIBlZWXp8OHDWrhwoRwOh5KTk1VaWuq9mFx1dbVCQr49FhAfH69XX31V9913ny655BLFxcVp1qxZmjNnTldtAgAARrJ4PB5PVw/ih3K5XLLZbHI6nYqMjOzq4QDwx2Lp6hEArdNO0yJzU/tjnwIATNJR8xKnuwMAAAAAYAhCOgAAAAAAhiCkAwAAAABgCEI6AAAAAACGIKQDAAAAAGAIQjoAAAAAAIYgpAMAAAAAYAhCOgAAAAAAhiCkAwAAAABgCEI6AAAAAACGIKQDAAAAAGAIQjoAAAAAAIYgpAMAAAAAYAhCOgAAAAAAhiCkAwAAAABgCEI6AAAAAACGIKQDAAAAAGAIQjoAAAAAAIYgpAMAAAAAYAhCOgAAAAAAhmhTSF+2bJkSEhJktVqVmpqqnTt3nrZ+/fr1GjZsmKxWq0aMGKEtW7Y0q9m7d69uuukm2Ww29e7dW6NGjVJ1dXVbhgcAAAAAQFAKOKSXlJQoLy9PBQUFqqysVFJSkjIyMlRbW+u3fseOHZo8ebKmTZum3bt3KzMzU5mZmdqzZ4+35qOPPtKVV16pYcOGafv27Xr//fe1YMECWa3Wtm8ZAAAAAABBxuLxeDyBdEhNTdWoUaO0dOlSSZLb7VZ8fLxmzpypuXPnNqvPyspSfX29Nm3a5G27/PLLlZycrOLiYknSpEmT1KNHD/3hD39o00a4XC7ZbDY5nU5FRka2aR0AOpjF0tUjAFonsGmxRcxN7Y99CgAwSUfNSwEdSW9sbFRFRYXsdvu3KwgJkd1uV3l5ud8+5eXlPvWSlJGR4a13u93avHmzLrroImVkZKh///5KTU3Vhg0bWhxHQ0ODXC6XzwIAAAAAQLALKKTX1dWpqalJ0dHRPu3R0dFyOBx++zgcjtPW19bW6tixY1q0aJGuv/56vfbaa7r55pv17//+73rjjTf8rrOwsFA2m827xMfHB7IZAAAAAAAYqcuv7u52uyVJEydO1H333afk5GTNnTtXP/7xj72nw39Xfn6+nE6ndzlw4EBnDhkAAAAAgA4RFkhxVFSUQkNDVVNT49NeU1OjmJgYv31iYmJOWx8VFaWwsDANHz7cp+biiy/W22+/7XedERERioiICGToAAAAAAAYL6Aj6eHh4Ro5cqTKysq8bW63W2VlZUpLS/PbJy0tzadekrZu3eqtDw8P16hRo7R//36fmg8++EADBw4MZHgAAAAAAAS1gI6kS1JeXp5ycnKUkpKi0aNHq6ioSPX19crNzZUkZWdnKy4uToWFhZKkWbNmKT09XYsXL9b48eO1bt067dq1S8uXL/euc/bs2crKytLVV1+tcePGqbS0VP/5n/+p7du3t89WAgAAAAAQBAIO6VlZWTp8+LAWLlwoh8Oh5ORklZaWei8OV11drZCQbw/QjxkzRmvXrtX8+fM1b948DRkyRBs2bFBiYqK35uabb1ZxcbEKCwv185//XEOHDtWf/vQnXXnlle2wiQAAAAAABIeA75NuIu6bCgQB7pOOYMF90o3FPgUAmMSI+6QDAAAAAICOQ0gHAAAAAMAQhHQAAAAAAAxBSAcAAAAAwBCEdAAAAAAADEFIBwAAAADAEIR0AAAAAAAMQUgHAAAAAMAQhHQAAAAAAAxBSAcAAAAAwBCEdAAAAAAADEFIBwAAAADAEIR0AAAAAAAMQUgHAAAAAMAQhHQAAAAAAAxBSAcAAAAAwBCEdAAAAAAADEFIBwAAAADAEIR0AAAAAAAMQUgHAAAAAMAQhHQAAAAAAAxBSAcAAAAAwBCEdAAAAAAADEFIBwAAAADAEIR0AAAAAAAMQUgHAAAAAMAQhHQAAAAAAAxBSAcAAAAAwBCEdAAA0CbLli1TQkKCrFarUlNTtXPnzlb1W7dunSwWizIzMzt2gAAABCFCOgAACFhJSYny8vJUUFCgyspKJSUlKSMjQ7W1taft9+mnn+qBBx7QVVdd1UkjBQAguBDSAQBAwJYsWaLp06crNzdXw4cPV3FxsXr16qVVq1a12KepqUm33XabHn74YQ0aNKgTRwsAQPAgpAMAgIA0NjaqoqJCdrvd2xYSEiK73a7y8vIW+z3yyCPq37+/pk2b1qrXaWhokMvl8lkAAOjuCOkAACAgdXV1ampqUnR0tE97dHS0HA6H3z5vv/22Vq5cqRUrVrT6dQoLC2Wz2bxLfHz8Dxo3AADBgJAOAAA61NGjRzV16lStWLFCUVFRre6Xn58vp9PpXQ4cONCBowQAwAxhXT0AAAAQXKKiohQaGqqamhqf9pqaGsXExDSr/+ijj/Tpp59qwoQJ3ja32y1JCgsL0/79+3XhhRc26xcREaGIiIh2Hj0AAGbjSDoAAAhIeHi4Ro4cqbKyMm+b2+1WWVmZ0tLSmtUPGzZMf/3rX1VVVeVdbrrpJo0bN05VVVWcxg4AwL/gSDoAAAhYXl6ecnJylJKSotGjR6uoqEj19fXKzc2VJGVnZysuLk6FhYWyWq1KTEz06d+vXz9JatYOAMCZjpAOAAAClpWVpcOHD2vhwoVyOBxKTk5WaWmp92Jy1dXVCgnhhD0AAAJl8Xg8nq4exA/lcrlks9nkdDoVGRnZ1cMB4I/F0tUjAFqnnaZF5qb2xz4FAJiko+Yl/sQNAAAAAIAhCOkAAAAAABiCkA4AAAAAgCEI6QAAAAAAGIKQDgAAAACAIQjpAAAAAAAYgpAOAAAAAIAhCOkAAAAAABiCkA4AAAAAgCHaFNKXLVumhIQEWa1WpaamaufOnaetX79+vYYNGyar1aoRI0Zoy5YtLdbeddddslgsKioqasvQAAAAAAAIWgGH9JKSEuXl5amgoECVlZVKSkpSRkaGamtr/dbv2LFDkydP1rRp07R7925lZmYqMzNTe/bsaVb7yiuv6J133lFsbGzgWwIAAAAAQJALOKQvWbJE06dPV25uroYPH67i4mL16tVLq1at8lv/zDPP6Prrr9fs2bN18cUX69FHH9Vll12mpUuX+tQdPHhQM2fO1Jo1a9SjR4+2bQ0AAAAAAEEsoJDe2NioiooK2e32b1cQEiK73a7y8nK/fcrLy33qJSkjI8On3u12a+rUqZo9e7Z+9KMfBTIkAAAAAAC6jbBAiuvq6tTU1KTo6Gif9ujoaO3bt89vH4fD4bfe4XB4H//yl79UWFiYfv7zn7dqHA0NDWpoaPA+drlcrd0EAAAAAACM1eVXd6+oqNAzzzyj1atXy2KxtKpPYWGhbDabd4mPj+/gUQIAAAAA0PECCulRUVEKDQ1VTU2NT3tNTY1iYmL89omJiTlt/VtvvaXa2lqdf/75CgsLU1hYmD777DPdf//9SkhI8LvO/Px8OZ1O73LgwIFANgMAAAAAACMFFNLDw8M1cuRIlZWVedvcbrfKysqUlpbmt09aWppPvSRt3brVWz916lS9//77qqqq8i6xsbGaPXu2Xn31Vb/rjIiIUGRkpM8CAAAAAECwC+g36ZKUl5ennJwcpaSkaPTo0SoqKlJ9fb1yc3MlSdnZ2YqLi1NhYaEkadasWUpPT9fixYs1fvx4rVu3Trt27dLy5cslSeecc47OOeccn9fo0aOHYmJiNHTo0B+6fQAAAAAABI2AQ3pWVpYOHz6shQsXyuFwKDk5WaWlpd6Lw1VXVysk5NsD9GPGjNHatWs1f/58zZs3T0OGDNGGDRuUmJjYflsBAAAAAEA3YPF4PJ6uHsQP5XK5ZLPZ5HQ6OfUdMFUrLwwJdLl2mhaZm9of+xQAYJKOmpe6/OruAAAAAADgFEI6AAAAAACGIKQDAAAAAGAIQjoAAAAAAIYgpAMAAAAAYAhCOgAAAAAAhiCkAwAAAABgCEI6AAAAAACGIKQDAAAAAGAIQjoAAAAAAIYgpAMAAAAAYAhCOgAAAAAAhiCkAwAAAABgCEI6AAAAAACGIKQDAAAAAGAIQjoAAAAAAIYgpAMAAAAAYAhCOgAAAAAAhiCkAwAAAABgCEI6AAAAAACGIKQDAAAAAGAIQjoAAAAAAIYgpAMAAAAAYAhCOgAAAAAAhiCkAwAAAABgCEI6AAAAAACGIKQDAAAAAGAIQjoAAAAAAIYgpAMAAAAAYAhCOgAAAAAAhiCkAwAAAABgCEI6AAAAAACGIKQDAAAAAGAIQjoAAAAAAIYgpAMAAAAAYAhCOgAAAAAAhiCkAwAAAABgCEI6AAAAAACGIKQDAAAAAGAIQjoAAGiTZcuWKSEhQVarVampqdq5c2eLtStWrNBVV12ls846S2eddZbsdvtp6wEAOFMR0gEAQMBKSkqUl5engoICVVZWKikpSRkZGaqtrfVbv337dk2ePFnbtm1TeXm54uPjdd111+ngwYOdPHIAAMxm8Xg8nq4exA/lcrlks9nkdDoVGRnZ1cMB4I/F0tUjAFqnnabF7j43paamatSoUVq6dKkkye12Kz4+XjNnztTcuXO/t39TU5POOussLV26VNnZ2a16ze6+TwEAwaWj5iWOpAMAgIA0NjaqoqJCdrvd2xYSEiK73a7y8vJWreP48eM6efKkzj777BZrGhoa5HK5fBYAALo7QjoAAAhIXV2dmpqaFB0d7dMeHR0th8PRqnXMmTNHsbGxPkH/uwoLC2Wz2bxLfHz8Dxo3AADBgJAOAAA61aJFi7Ru3Tq98sorslqtLdbl5+fL6XR6lwMHDnTiKAEA6BphXT0AAAAQXKKiohQaGqqamhqf9pqaGsXExJy279NPP61Fixbp9ddf1yWXXHLa2oiICEVERPzg8QIAEEw4kg4AAAISHh6ukSNHqqyszNvmdrtVVlamtLS0Fvs9+eSTevTRR1VaWqqUlJTOGCoAAEGHI+kAACBgeXl5ysnJUUpKikaPHq2ioiLV19crNzdXkpSdna24uDgVFhZKkn75y19q4cKFWrt2rRISEry/Xe/Tp4/69OnTZdsBAIBpCOkAACBgWVlZOnz4sBYuXCiHw6Hk5GSVlpZ6LyZXXV2tkJBvT9h77rnn1NjYqFtuucVnPQUFBXrooYc6c+gAABitTae7L1u2TAkJCbJarUpNTdXOnTtPW79+/XoNGzZMVqtVI0aM0JYtW7zPnTx5UnPmzNGIESPUu3dvxcbGKjs7W59//nlbhgYAADrJPffco88++0wNDQ169913lZqa6n1u+/btWr16tffxp59+Ko/H02whoAMA4CvgkF5SUqK8vDwVFBSosrJSSUlJysjIUG1trd/6HTt2aPLkyZo2bZp2796tzMxMZWZmas+ePZJO3Se1srJSCxYsUGVlpV5++WXt379fN9100w/bMgAAAAAAgozF4/F4AumQmpqqUaNGaenSpZJOXSgmPj5eM2fO1Ny5c5vVZ2Vlqb6+Xps2bfK2XX755UpOTlZxcbHf13jvvfc0evRoffbZZzr//PO/d0wul0s2m01Op1ORkZGBbA6AzmKxdPUIgNYJbFpsEXNT+2OfAgBM0lHzUkBH0hsbG1VRUSG73f7tCkJCZLfbVV5e7rdPeXm5T70kZWRktFgvSU6nUxaLRf369QtkeAAAAAAABLWALhxXV1enpqYm70VhvhEdHa19+/b57eNwOPzWf3NV1+86ceKE5syZo8mTJ7f414iGhgY1NDR4H7tcrkA2AwAAAAAAIxl1n/STJ0/q1ltvlcfj0XPPPddiXWFhoWw2m3eJj4/vxFECAAAAANAxAgrpUVFRCg0NVU1NjU97TU2NYmJi/PaJiYlpVf03Af2zzz7T1q1bT3tOf35+vpxOp3c5cOBAIJsBAAAAAICRAgrp4eHhGjlypMrKyrxtbrdbZWVlSktL89snLS3Np16Stm7d6lP/TUD/8MMP9frrr+ucc8457TgiIiIUGRnpswAAAAAAEOwC+k26JOXl5SknJ0cpKSkaPXq0ioqKVF9fr9zcXElSdna24uLiVFhYKEmaNWuW0tPTtXjxYo0fP17r1q3Trl27tHz5ckmnAvott9yiyspKbdq0SU1NTd7fq5999tkKDw9vr20FAAAAAMBoAYf0rKwsHT58WAsXLpTD4VBycrJKS0u9F4errq5WSMi3B+jHjBmjtWvXav78+Zo3b56GDBmiDRs2KDExUZJ08OBBbdy4UZKUnJzs81rbtm3T2LFj27hpAAAAAAAEl4Dvk24i7psKBAHuk45gwX3SjcU+BQCYxIj7pAMAAAAAgI5DSAcAAAAAwBCEdAAAAAAADEFIBwAAAADAEIR0AAAAAAAMQUgHAAAAAMAQhHQAAAAAAAxBSAcAAAAAwBCEdAAAAAAADEFIBwAAAADAEIR0AAAAAAAMQUgHAAAAAMAQhHQAAAAAAAxBSAcAAAAAwBCEdAAAAAAADEFIBwAAAADAEIR0AAAAAAAMQUgHAAAAAMAQhHQAAAAAAAxBSAcAAAAAwBCEdAAAAAAADEFIBwAAAADAEIR0AAAAAAAMQUgHAAAAAMAQhHQAAAAAAAxBSAcAAAAAwBCEdAAAAAAADEFIBwAAAADAEIR0AAAAAAAMQUgHAAAAAMAQhHQAAAAAAAxBSAcAAAAAwBCEdAAAAAAADEFIBwAAAADAEIR0AAAAAAAMQUgHAAAAAMAQhHQAAAAAAAxBSAcAAAAAwBCEdAAAAAAADEFIBwAAAADAEIR0AAAAAAAMQUgHAAAAAMAQhHQAAAAAAAxBSAcAAAAAwBCEdAAAAAAADEFIBwAAAADAEIR0AAAAAAAMQUgHAAAAAMAQhHQAAAAAAAzRppC+bNkyJSQkyGq1KjU1VTt37jxt/fr16zVs2DBZrVaNGDFCW7Zs8Xne4/Fo4cKFGjBggHr27Cm73a4PP/ywLUMDAACdpL2/DwAAgDaE9JKSEuXl5amgoECVlZVKSkpSRkaGamtr/dbv2LFDkydP1rRp07R7925lZmYqMzNTe/bs8dY8+eST+vWvf63i4mK9++676t27tzIyMnTixIm2bxkAAOgwHfF9AAAASBaPx+MJpENqaqpGjRqlpUuXSpLcbrfi4+M1c+ZMzZ07t1l9VlaW6uvrtWnTJm/b5ZdfruTkZBUXF8vj8Sg2Nlb333+/HnjgAUmS0+lUdHS0Vq9erUmTJn3vmFwul2w2m5xOpyIjIwPZHACdxWLp6hEArRPYtNii7j43tff3gdbo7vsUABBcOmpeCgukuLGxURUVFcrPz/e2hYSEyG63q7y83G+f8vJy5eXl+bRlZGRow4YNkqRPPvlEDodDdrvd+7zNZlNqaqrKy8v9hvSGhgY1NDR4HzudTkmndhIAAD9IO80l38xJAf4tPCh0xPcBf5jvAQAm66i5PqCQXldXp6amJkVHR/u0R0dHa9++fX77OBwOv/UOh8P7/DdtLdV8V2FhoR5++OFm7fHx8a3bEAAAWmKztevqjh49Kls7r7OrdcT3AX+Y7wEAweB///d/23WuDyikmyI/P9/nr/Fut1tffPGFzjnnHFk4pdZILpdL8fHxOnDgAKcoAu2E95XZPB6Pjh49qtjY2K4eStD67nx/5MgRDRw4UNXV1d3uDx9dgc+Q9sc+bV/sz/bHPm1fTqdT559/vs4+++x2XW9AIT0qKkqhoaGqqanxaa+pqVFMTIzfPjExMaet/+a/NTU1GjBggE9NcnKy33VGREQoIiLCp61fv36BbAq6SGRkJB8IQDvjfWWu7hokO+L7gD/+5nvp1H7l//n2w2dI+2Ofti/2Z/tjn7avkJD2vbN5QGsLDw/XyJEjVVZW5m1zu90qKytTWlqa3z5paWk+9ZK0detWb/0FF1ygmJgYnxqXy6V33323xXUCAICu0xHfBwAAwCkBn+6el5ennJwcpaSkaPTo0SoqKlJ9fb1yc3MlSdnZ2YqLi1NhYaEkadasWUpPT9fixYs1fvx4rVu3Trt27dLy5cslSRaLRffee68ee+wxDRkyRBdccIEWLFig2NhYZWZmtt+WAgCAdtPe3wcAAMApAYf0rKwsHT58WAsXLpTD4VBycrJKS0u9F4Oprq72Odw/ZswYrV27VvPnz9e8efM0ZMgQbdiwQYmJid6aBx98UPX19frpT3+qI0eO6Morr1RpaamsVms7bCJMEBERoYKCAr+nLQJoG95X6Eod8X3g+/D/fPtif7Y/9mn7Yn+2P/Zp++qo/RnwfdIBAAAAAEDHaN9fuAMAAAAAgDYjpAMAAAAAYAhCOgAAAAAAhiCkn6G2b98ui8WiI0eOnLYuISFBRUVFnTIm4EzCexAAAAD+ENKDXHFxsfr27auvv/7a23bs2DH16NFDY8eO9an9JhR89NFHGjNmjA4dOiSbzSZJWr16tfr169eJI/fV2iCSkJAgi8Uii8Wi3r1767LLLtP69et9alwul37xi19o2LBhslqtiomJkd1u18svv6zvXifxxRdfVGhoqGbMmNGem4MziInvwTvuuMP7PgkPD9fgwYP1yCOP+IzR4/Fo+fLlSk1NVZ8+fdSvXz+lpKSoqKhIx48f91nfP//5T4WHhwd0FW6grZYtW6aEhARZrValpqZq586dp61fv3699/N+xIgR2rJlSyeNNDgEsj9XrFihq666SmeddZbOOuss2e32793/Z6JA/x/9xrp162SxWLjF8HcEuj+PHDmiGTNmaMCAAYqIiNBFF13E+/47At2nRUVFGjp0qHr27Kn4+Hjdd999OnHiRCeN1mxvvvmmJkyYoNjYWFksFm3YsOF7+2zfvl2XXXaZIiIiNHjwYK1evTrg1yWkB7lx48bp2LFj2rVrl7ftrbfeUkxMjN59912fN9i2bdt0/vnn68ILL1R4eLhiYmJksVi6Ytg/yCOPPKJDhw5p9+7dGjVqlLKysrRjxw5Jpz64x4wZo+eff175+fmqrKzUm2++qaysLD344INyOp0+61q5cqUefPBBvfjii3wYoU1MfQ9ef/31OnTokD788EPdf//9euihh/TUU095n586daruvfdeTZw4Udu2bVNVVZUWLFigP//5z3rttdd81rV69WrdeuutcrlcevfddztkvIAklZSUKC8vTwUFBaqsrFRSUpIyMjJUW1vrt37Hjh2aPHmypk2bpt27dyszM1OZmZnas2dPJ4/cTIHuz+3bt2vy5Mnatm2bysvLFR8fr+uuu04HDx7s5JGbK9B9+o1PP/1UDzzwgK666qpOGmlwCHR/NjY26tprr9Wnn36ql156Sfv379eKFSsUFxfXySM3V6D7dO3atZo7d64KCgq0d+9erVy5UiUlJZo3b14nj9xM9fX1SkpK0rJly1pV/8knn2j8+PEaN26cqqqqdO+99+rOO+/Uq6++GtgLexD0BgwY4CksLPQ+fvDBBz0zZszwXHzxxZ5t27Z526+++mpPTk6Ox+PxeLZt2+aR5Pnyyy+9//7XpaCgwOPxeDwDBw70PP74457c3FxPnz59PPHx8Z7f/va3Pq///vvve8aNG+exWq2es88+2zN9+nTP0aNHvc+np6d7Zs2a5dNn4sSJ3rGkp6c3e/2WDBw40POrX/3K+/jkyZOeXr16eebOnevxeDyeu+++29O7d2/PwYMHm/U9evSo5+TJk97HH3/8sadnz56eI0eOeFJTUz1r1qxp8XWB0+nq9+B35eTkeCZOnOjTdu2113ouv/xyj8fj8ZSUlHgkeTZs2NCsr9vt9hw5csTn8aBBgzylpaWeOXPmeKZPnx7AngECM3r0aM+MGTO8j5uamjyxsbE+769/deutt3rGjx/v05aamur5f//v/3XoOINFoPvzu77++mtP3759Pb///e87aohBpy379Ouvv/aMGTPG87vf/c7v5/OZLND9+dxzz3kGDRrkaWxs7KwhBp1A9+mMGTM811xzjU9bXl6e54orrujQcQYjSZ5XXnnltDUPPvig50c/+pFPW1ZWlicjIyOg1+JIejcwbtw4bdu2zft427ZtGjt2rNLT073tX331ld59912NGzeuWf8xY8aoqKhIkZGROnTokA4dOqQHHnjA+/zixYuVkpKi3bt362c/+5nuvvtu7d+/X9Kpvy5lZGTorLPO0nvvvaf169fr9ddf1z333NPq8b/88ss677zzvEfIDx061Oq+YWFh6tGjhxobG+V2u7Vu3Trddtttio2NbVbbp08fhYWFeR//x3/8h8aPHy+bzabbb79dK1eubPXrAv+qK9+DrdWzZ081NjZKktasWaOhQ4dq4sSJzeosFov3FPxvtuX48eOy2+26/fbbtW7dOtXX1wf02kBrNDY2qqKiQna73dsWEhIiu92u8vJyv33Ky8t96iUpIyOjxfozSVv253cdP35cJ0+e1Nlnn91Rwwwqbd2njzzyiPr3769p06Z1xjCDRlv258aNG5WWlqYZM2YoOjpaiYmJeuKJJ9TU1NRZwzZaW/bpmDFjVFFR4T0l/uOPP9aWLVt04403dsqYu5v2mpcI6d3AuHHj9Je//EVff/21jh49qt27dys9PV1XX321tm/fLunU/zANDQ1+A0J4eLhsNpssFotiYmIUExOjPn36eJ+/8cYb9bOf/UyDBw/WnDlzFBUV5Q0ea9eu1YkTJ/T8888rMTFR11xzjZYuXao//OEPqqmpadX4zz77bIWGhqpv377e12+NxsZGFRYWyul06pprrlFdXZ2+/PJLDRs27Hv7ut1urV69WrfffrskadKkSXr77bf1ySeftOq1gX/Vle/B7+PxePT666/r1Vdf1TXXXCNJ+vDDDzV06NBW9V+5cqUmTZqk0NBQJSYmatCgQc2uAwG0h7q6OjU1NSk6OtqnPTo6Wg6Hw28fh8MRUP2ZpC3787vmzJmj2NjYZl84z1Rt2advv/22Vq5cqRUrVnTGEINKW/bnxx9/rJdeeklNTU3asmWLFixYoMWLF+uxxx7rjCEbry37dMqUKXrkkUd05ZVXqkePHrrwwgs1duxYTndvo5bmJZfLpa+++qrV6yGkdwNjx45VfX293nvvPb311v/X3t2FRPG9cQB/WnV8FynfVtRg3TYt1MBKREqMvIjIm35oN0tdlJR4F5IgoWGWhRQRqRRaXkQWoUhKUpoLf7QoaDOpTSmzCDXEFGy98GW+/4twaFtNVyq3/H5gwT3O2TnzsGd3ntkz5/xPTCaThIaGSnp6unZPrMViEYPBIDExMS6/fmJiovb3XBIxd1+LzWaTpKQk8ff317ZJS0sTVVVd/qVvqU6cOCEBAQHi5+cn586dk/Lyctm7d6/TpHA/8/DhQ7Hb7dpVwpCQEMnMzJTa2trf0mb6t61kH1xIc3OzBAQEiI+Pj+zZs0dycnKkpKRERGTJfWV8fFwaGhq0i1kiwlEnRKtEeXm51NfXS2Njo/j4+Kx0c/5KExMTYjab5dq1axISErLSzfknqKoqYWFhcvXqVUlOTpacnBwpKiqS6urqlW7aX8tisciZM2eksrJSnj9/Lg0NDdLS0iKlpaUr3bRVzXPxTcjdGY1GiYqKko6ODhkbG5P09HQREYmMjJTo6Gjp6uqSjo4O7Vc0V3l5eTk8X7NmjaiquuT6Op3OKSmYnp5eVltERAoKCuTQoUMSEBAg4eHh2sRboaGhEhwcLG/evFn0NWpqauTLly/i6+urlamqKi9fvpRTp06JTsfrV7R07tgHMzIypKqqShRFkcjISIdbPUwm05L6ydxImZSUFK0MgKiqKn19fWIymVw8EqKFhYSEiIeHh9MorM+fPy84wioiIsKl7VeT5cRzTkVFhZSXl0tbW5vDRcLVztWYvnv3TgYGBmTfvn1a2dxnt6enp/T29kpsbOzvbbQbW857VK/Xi5eXl3h4eGhl8fHxMjw8LFNTU6Ioym9ts7tbTkxPnjwpZrNZDh8+LCIiCQkJYrfbJTc3V4qKinhO7KKFvpeCgoIc8o7FMOr/iIyMDLFYLGKxWByWfdq5c6fcv39fnj59Ou8w2zmKoizrfp74+Hjp7u52uEe1s7NTdDqdNpw2NDTU4T7z2dlZp5l3Xdl/SEiIGI1Gp5mxdTqdHDhwQG7evCmDg4NO9b5+/SozMzMyOjoqTU1NUl9fLy9evNAeVqtVxsbGnGa2JlqKleqDC/H39xej0SgxMTEOCbrIt6FtfX190tTU5FQPgLYKQk1NjRw/ftyhn3R3d8uOHTs46oR+OUVRJDk5Wdrb27UyVVWlvb1dUlNT562TmprqsL3It5FSC22/miwnniIi58+fl9LSUmltbZWtW7f+iab+NVyNaVxcnPT09Dh8hmZlZWmzPkdHR//J5rud5bxH09LS5O3btw4Xqvv6+kSv16/6BF1keTGdnJx0SsTnLoK4MkqVvvll30suTTNHbqu2tha+vr7w9PTE8PCwVl5XV4fAwECICAYHB7Xy72eWBoDOzk6ICNra2jAyMgK73Q7AeTZ1AEhKStJmnrbb7dDr9di/fz96enrw6NEjGAwGbQZrAKiuroafnx+am5ths9lw5MgRBAUFOWyTmZmJrKwsfPr0CSMjIwse53zt+d7o6Cji4uIQFRWFuro6vHr1Cn19faipqYHRaMTY2BguXrwIvV4PVVWd6mdnZ+O///5b8PWJFrJSfXA+i80erKoqcnJy4Ovri7KyMjx79gwDAwO4d+8edu3ahcbGRlitVogIbDabU/3KykpEREQ4rJZA9CvU19fD29sbN27cwOvXr5Gbm4vg4GCtT5nNZm01D+Bbv/H09ERFRQVsNhuKi4vh5eWFnp6elToEt+JqPMvLy6EoCu7evYuhoSHt8f2KLaudqzH9EWd3d+RqPD9+/IjAwEDk5+ejt7cXzc3NCAsLw+nTp1fqENyOqzEtLi5GYGAgbt26hf7+fjx48ACxsbHIzs5eqUNwKxMTE7Bardp50YULF2C1WvHhwwcAQGFhIcxms7Z9f38//Pz8UFBQAJvNhitXrsDDwwOtra0u7ZdJ+j/i/fv3EBHExcU5lA8MDEBEsHHjRofyHxMEADh69CjWrVvntPzTYgnCYkuwTU1N4dixY1i7di3CwsJw9uxZhyXYAODx48dITEyEt7e3S0uwzWd8fByFhYXYsGEDFEVBeHg4du/ejcbGRqiqioSEBOTl5c1b9/bt21AU5acXCojms5J98EdLOQmcnZ1FVVUVtm3bBj8/PwQFBSE5ORmXLl3C5OQk8vPzsWnTpnnrDg0NQafToamp6af7IFqOy5cvIyYmBoqiYPv27Xjy5In2v/T0dIfvDgC4c+cOTCYTFEXB5s2b0dLS8odb7N5cief69eudloP8/vOIvnH1Pfo9JunOXI1nV1cXUlJS4O3tDYPBgLKyMszMzPzhVrs3V2I6PT2NkpISxMbGwsfHB9HR0cjLy3M4P1nN5lsmV0S0GB48eBDp6elOdbZs2QJFUWAwGHD9+nWX97sG4DgGIiIiIiIiInfAe9KJiIiIiIiI3ASTdCIiIiIiIiI3wSSdiIiIiIiIyE0wSSciIiIiIiJyE0zSiYiIiIiIiNwEk3QiIiIiIiIiN8EknYiIiIiIiMhNMEknIiIiIiIichNM0omIiIiIiIjcBJN0IiIiIiIiIjfBJJ2IiIiIiIjITTBJJyIiIiIiInIT/wcJckwABo2MAAAAAABJRU5ErkJggg==\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Create a figure\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(12, 10))\n",
    "\n",
    "# Plot the RMSE\n",
    "axes[0,0].bar(['Without PCA', 'With PCA'], [rmse,rmse_pca], color=['b', 'r'], align='center')\n",
    "axes[0,0].set_title(\"RMSE\")\n",
    "axes[0,0].set_xticks(['Without PCA', 'With PCA'])\n",
    "\n",
    "# Plot the R2\n",
    "axes[0,1].bar(['Without PCA', 'With PCA'], [r2,r2_pca], color=['b', 'r'], align='center')\n",
    "axes[0,1].set_title(\"R2\")\n",
    "axes[0,1].set_xticks(['Without PCA', 'With PCA'])\n",
    "\n",
    "# Plot the MAE\n",
    "axes[1,0].bar(['Without PCA', 'With PCA'], [mae,mae_pca], color=['b', 'r'], align='center')\n",
    "axes[1,0].set_title(\"MAE\")\n",
    "axes[1,0].set_xticks(['Without PCA', 'With PCA'])\n",
    "\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "I would choose to use the linear regression model with PCA for this dataset. This is because the RMSE, R2, and MAE are all lower for the linear regression with PCA model, which means that this model is a better fit for the data."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
